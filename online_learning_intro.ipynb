{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdu√ß√£o (n√£o-extensiva) a Online Learning\n",
    "\n",
    "\n",
    "**Saulo Martiello Mastelini** (mastelini@usp.br)\n",
    "\n",
    "Outras redes:\n",
    "\n",
    "- [Github](https://github.com/smastelini)\n",
    "- [Linkedin](https://www.linkedin.com/in/smastelini/) (eu deveria, mas n√£o atualizo frequentemente -- para ser sincero, est√° muito desatualizado)\n",
    "- [ResearchGate](https://www.researchgate.net/profile/Saulo-Mastelini)\n",
    "\n",
    "MBA em Ci√™ncia de Dados<br>\n",
    "Universidade de S√£o Paulo, S√£o Carlos, Brasil<br>\n",
    "Copyright (c) 2021\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer**\n",
    "\n",
    "Como o t√≠tulo j√° diz, essa n√£o √©, de forma alguma, uma introdu√ß√£o extensiva ao tema. √â apenas a minha humilde tentativa de dar um panorama geral de d√©cadas de pesquisa em uma √°rea que est√° em constante expans√£o e inova√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Sum√°rio\n",
    "1. Online learning? Why?\n",
    "2. Batch vs. Online\n",
    "3. Estruturas necess√°rias: exemplo\n",
    "    - Mean\n",
    "    - Var\n",
    "    - Quantile\n",
    "4. Por que usar dicion√°rios?\n",
    "    - Exemplos com dados faltantes\n",
    "5. Como avaliar um modelo?\n",
    "    - `progressive_val_score`\n",
    "    - label delay\n",
    "6. Exemplos de algoritmos\n",
    "    1. Classifica√ß√£o\n",
    "        1. Logistic regression\n",
    "        2. Hoeffding Tree\n",
    "        3. Naive Bayes\n",
    "        4. Adaptive Random Forest\n",
    "        5. Streaming Random Patches\n",
    "    2. Regress√£o\n",
    "        1. Linear Regression\n",
    "        2. Hoeffding Tree\n",
    "        3. Stochastic Gradient Trees\n",
    "        4. AMRules\n",
    "        5. Adaptive Random Forest\n",
    "        6. Streaming Random Forest\n",
    "    3. Clustering\n",
    "        1. k-Means\n",
    "        2. CluStream\n",
    "        3. DenStream\n",
    "        4. DBSTREAM\n",
    "    4. Anomaly detection\n",
    "        1. Half-space Trees\n",
    "7. Expert module\n",
    "8. Pipelines e pr√©-processamento\n",
    "    - Encoding\n",
    "    - Scaling\n",
    "    - Filtragem e Sele√ß√£o\n",
    "    - Aritm√©tica com Pipelines\n",
    "    - Visualizando as coisas\n",
    "9. Exemplo completo\n",
    "    - processamento em tempo real\n",
    "    - inspe√ß√£o de modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Online Learning? Why?\n",
    "\n",
    "Por que algu√©m deveria se preocupar em atualizar modelos a todo tempo? N√£o √© s√≥ treinar e sair usando?\n",
    "\n",
    "R: sim! Em grande parte dos casos isso √© verdade.\n",
    "\n",
    "Mas imagine que:\n",
    "\n",
    "- A quantidade de dados produzidas √© enorme\n",
    "- N√£o √© poss√≠vel armazenar tudo\n",
    "- Existe limita√ß√£o no poder computacional para treinamento dos modelos\n",
    "    - processador\n",
    "    - mem√≥ria\n",
    "    - bateria\n",
    "- Os dados s√£o n√£o-estacion√°rios e/ou evoluem com o tempo\n",
    "\n",
    "Nesses casos, posso usar aprendizado de m√°quina tradicional? R: sim!!\n",
    "\n",
    "√â poss√≠vel usar aprendizado de m√°quina tradicional se:\n",
    "- Os dados s√£o estacion√°rios (uma amostra representativa dos dados √© suficiente)\n",
    "\n",
    "ou\n",
    "\n",
    "- A velocidade de produ√ß√£o dos dados n√£o √© t√£o alta (batch-incremental e os recursos computacionais s√£o suficientes\n",
    "\n",
    "## 1.1 Batch-incremental\n",
    "\n",
    "\n",
    "Um modelo tradicional de aprendizado de m√°quina √© re-treinado de tempos em tempos. Para tal, uma janela para treinamento precisa ser definida.\n",
    "\n",
    "Tipos de janelamento dos dados:\n",
    "\n",
    "\n",
    "<img src=\"time_windows.png\">\n",
    "\n",
    "**Fonte:** Adaptado de:\n",
    "\n",
    "> Carnein, M. and Trautmann, H., 2019. Optimizing data stream representation: An extensive survey on stream clustering algorithms. Business & Information Systems Engineering, 61(3), pp.277-297.\n",
    "\n",
    "- *Landmarks* s√£o a escolha mais comum em estrat√©gias batch-incremental. √â preciso definir o tamanho da janela de forma adequada.\n",
    "    - O modelo pode ficar defasado se a janela for muito grande \n",
    "    - Ou o modelo pode n√£o capturar os padr√µes se a janela for muito pequena\n",
    "    - Concept-drift √© um problema e tanto\n",
    "    \n",
    "**Aten√ß√£o**: batch-incremental != mini-batch.\n",
    "Redes neurais podem ser treinadas de forma incremental ou progressiva. No entanto, quest√µes como \"esquecimento catastr√≥fico\" s√£o problem√°ticas. Esse e outros tipos de desafios s√£o tratados na √°rea de pesquisa chamada **continual learning**.\n",
    "\n",
    "## 1.2 Importante lembrar\n",
    "\n",
    "Data streams n√£o s√£o, necessariamente, s√©ries temporais! ü§Ø\n",
    "\n",
    "Mas qual √© a diferen√ßa, ent√£o?\n",
    "\n",
    "Basicamente, em streams n√£o necessariamente temos depend√™ncias temporais expl√≠citas como em s√©ries temporais. Por exemplo: rede de sensores.\n",
    "\n",
    "Os dados chegam temporalmente organizados, mas cada sensor tem uma taxa de transmiss√£o espec√≠fica, ou um delay espec√≠fico. Alguns sensores pode falhar... outros serem adicionados. E assim por diante.\n",
    "\n",
    "A ordem de chegada n√£o importa... tanto, mas importa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Batch vs. Online\n",
    "\n",
    "Uma boa introdu√ß√£o acerca da \"migra√ß√£o\" de batch para online est√° dispon√≠vel no [site](https://riverml.xyz/latest/examples/batch-to-online/) do River. Aqui eu s√≥ quero dar uma vis√£o bem geral das diferen√ßas. Entraremos em mais detalhes posteriormente nas min√∫cias de avalia√ß√£o de modelos em Online Learning.\n",
    "\n",
    "\n",
    "Uma poss√≠vel valida√ß√£o de um modelo tradicional de aprendizado de m√°quina poderia ter essa \"cara\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia m√©dia: 0.9045751633986928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = load_wine()\n",
    "\n",
    "X, y = data.data, data.target\n",
    "kf = KFold(shuffle=True, random_state=8, n_splits=10)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_tr, X_ts = X[train], X[test]\n",
    "    y_tr, y_ts = y[train], y[test]\n",
    "    \n",
    "    dt  = DecisionTreeClassifier(max_depth=5, random_state=93)\n",
    "    dt.fit(X_tr, y_tr)\n",
    "    \n",
    "    accs.append(accuracy_score(y_ts, dt.predict(X_ts)))\n",
    "\n",
    "print(f\"Acur√°cia m√©dia: {sum(accs) / len(accs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparem que todo o conjunto de dados est√° dispon√≠vel e carregado em mem√≥ria. O algoritmo de √°rvore de decis√£o pode percorrer os dados de treino quantas vezes forem necess√°rias. Os dados de teste (valida√ß√£o, no nosso caso) nunca s√£o utilizados para treino.\n",
    "\n",
    "No fim das contas, usar√≠amos o conjunto completo para treinar um modelo final (supondo que j√° encontramos um conjunto adequado de hiper-par√¢metros). Uma vez treinado, esse modelo seria utilizado para fazer predi√ß√µes para novas amostras (de vinhos, nesse caso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 0.9269662921348315\n"
     ]
    }
   ],
   "source": [
    "from river import metrics\n",
    "from river import stream\n",
    "from river import tree\n",
    "\n",
    "\n",
    "acc = metrics.Accuracy()\n",
    "ht = tree.HoeffdingTreeClassifier(max_depth=5, grace_period=20)\n",
    "\n",
    "for x, y in stream.iter_sklearn_dataset(load_wine()):\n",
    "    # M√©trica atualizada antes do treinamento\n",
    "    acc.update(y, ht.predict_one(x))\n",
    "    # Modelo treinado amostra-a-amostra\n",
    "    ht.learn_one(x, y)\n",
    "\n",
    "print(f\"Acur√°cia: {acc.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, estamos percorrendo cada exemplo do conjunto de dados de forma sequencial. Os exemplos poderiam ser carregados diretamente do disco, de algum webservice, ou de onde sua imagina√ß√£o te levar, sem a necessidade de salvar em mem√≥ria nada.\n",
    "\n",
    "Cada amostra √© primeiramente utilizada para teste e depois passada para o modelo. Tudo √© atualizado uma amostra por vez. Notem que n√£o podemos comparar diretamente os desempenhos obtidos porque a estrat√©gia de avalia√ß√£o foi diferente nos dois casos.\n",
    "\n",
    "Poder√≠amos ainda (pseudo) embaralhar os dados antes de passar para o modelo, se temos plena confian√ßa que os dados s√£o estacion√°rios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estruturas necess√°rias: exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from river import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado esse choque inicial, vamos prosseguir com calma e primeiramente pensar em alguns aspectos importantes antes de vermos os algoritmos de aprendizado de m√°quina online.\n",
    "\n",
    "## 3.1. Um exemplo, para aquecimento cerebral\n",
    "\n",
    "Vamos supor que queremos calcular estat√≠sticas para dados que chegam a todo momento:\n",
    "\n",
    "- M√©dia\n",
    "- Vari√¢ncia\n",
    "- ...\n",
    "\n",
    "Hora de simular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 27.5 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valores = []\n",
    "stds_batch = []\n",
    "\n",
    "for _ in range(50000):\n",
    "    v = rng.gauss(5, 3)\n",
    "    valores.append(v)\n",
    "    \n",
    "    stds_batch.append(np.std(valores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padr√£o o numpy calcula o desvio padr√£o populacional! Para usar a vers√£o amostral precisamos passar `ddof=1` como par√¢metro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 ms, sys: 0 ns, total: 107 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stds_incr = []\n",
    "var = stats.Var(ddof=0)\n",
    "\n",
    "for _ in range(50000):\n",
    "    v = rng.gauss(5, 3)\n",
    "    var.update(v)\n",
    "    stds_incr.append(var.get() ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√° que d√° alguma diferen√ßa? E ser√° que funciona?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.301100448023121e-10, 8.602200896046241e-15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_erros = 0\n",
    "\n",
    "for batch, incr in zip(stds_batch, stds_incr):\n",
    "    s_erros += (batch - incr)\n",
    "\n",
    "s_erros, s_erros / len(stds_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... parece convincente. Mas e se o cen√°rio fosse diferente? Se ao inv√©s de calcularmos o desvio padr√£o e irmos aumentando a quantidade de dados, quisessemos descobrir um percentil das √∫ltimas `N` amostras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)\n",
    "\n",
    "tam = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.1 s, sys: 27.4 ms, total: 54.1 s\n",
      "Wall time: 54.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "buffer = []\n",
    "percs75_batch = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    v = rng.uniform(-100, 100)\n",
    "    buffer.append(v)\n",
    "    if len(buffer) <= tam:\n",
    "        continue\n",
    "        \n",
    "    percs75_batch.append(np.quantile(buffer, q=0.75))\n",
    "    buffer.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos fazer um pouco melhor que isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.55 s, sys: 0 ns, total: 5.55 s\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "qtl = stats.RollingQuantile(window_size=tam, q=0.75)\n",
    "percs75_incr = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    v = rng.uniform(-100, 100)\n",
    "    qtl.update(v)\n",
    "    if len(qtl) <= tam:\n",
    "        continue\n",
    "        \n",
    "    percs75_incr.append(qtl.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_erros = 0\n",
    "\n",
    "for batch, incr in zip(percs75_batch, percs75_incr):\n",
    "    s_erros += (batch - incr)\n",
    "\n",
    "s_erros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero t√™-los convencido! O [m√≥dulo](https://riverml.xyz/dev/api/overview/#stats) `stats` do River tem v√°rias fun√ß√µes √∫teis para sumariza√ß√£o de dados de forma incremental. Vale a pena checar! üßê\n",
    "\n",
    "A raz√£o pela qual eu quis mostrar tudo isso √© porque v√°rios desses algoritmos s√£o os \"tijolos\" que comp√µem os algoritmos de aprendizado de m√°quina. Uma receita breve para online learning:\n",
    "\n",
    "- A jun√ß√£o de m√©tricas estat√≠sticas incrementais\n",
    "- Algumas grandezas probabil√≠sticas\n",
    "- Algumas teorias de aprendizado de m√°quina que s√£o gen√©ricas e n√£o limitadas ao cen√°rio in-batch\n",
    "- Gradiente descendente\n",
    "- *otras cositas*\n",
    "\n",
    "Com isso tudo √© poss√≠vel formar boa parte dos algoritmos de aprendizado incremental. Mas isso √© extremamente gen√©rico de se dizer, n√£o √©? Bom, no fim das contas, o aprendizado de m√°quina tradicional tamb√©m \"se resume\" a algumas coisas pontuais, mas que s√£o extremamente abrangentes por si s√≥.\n",
    "\n",
    "Que tal entendermos um pouco de como os exemplos anteriores funcionam e por que eles funcionam?\n",
    "\n",
    "## 3.2. Uma (extremamente) breve reflex√£o sobre complexidade dos algoritmos\n",
    "\n",
    "Quanto custa para calcular a vari√¢ncia (no caso, desvio padr√£o) e o percentil nos exemplos anteriores?\n",
    "\n",
    "**Modo batch**\n",
    "\n",
    "Vari√¢ncia:  $\\dfrac{\\sum_i^N (x_i - \\bar{x})}{N - 1}$\n",
    "\n",
    "- M√©dia √© calculada com o custo $O(n)$ -> todos os elementos devem ser somados e divididos pelo total de observa√ß√µes\n",
    "- Com a m√©dia em m√£os, precisamos calcular o desvio de cada elemento para a m√©dia e somar tais desvios: $O(n)$\n",
    "- No fim das contas, o custo final √© $O(n)$ (na nota√ß√£o assint√≥tica), mas tivemos que percorrer todos os dados duas vezes (e, consequentemente, armazen√°-los).\n",
    "- Esse algoritmo tamb√©m apresenta problemas de estabilidade, quando o n√∫mero de observa√ß√µes √© muito grande. Pode gerar erros num√©ricos de aproxima√ß√£o.\n",
    "\n",
    "Percentil:\n",
    "\n",
    "- Pegue um exemplo novo e remova o mais antigo\n",
    "- Ordene os dados: algo em torno de $O(n\\log n)$ (n √© o tamanho do buffer)\n",
    "- Encontre a posi√ß√£o correta, interpole e retorne\n",
    "\n",
    "Se esse processo √© repetido v√°rias e v√°rias vezes...\n",
    "\n",
    "**Modo incremental**\n",
    "\n",
    "\n",
    "Vari√¢ncia (algoritmo de Welford):\n",
    "\n",
    "- Precisamos de algumas vari√°veis:\n",
    "    - $n$: n√∫mero de observa√ß√µes\n",
    "    - $\\overline{x}_n$: a m√©dia da amostral, ap√≥s $n$ observa√ß√µes\n",
    "    - $M_{2, n}$: estat√≠stica de segunda ordem que gerar√° a vari√¢ncia\n",
    "- As atualiza√ß√µes das estat√≠sticas se d√£o na seguinte forma:\n",
    "    - $\\overline{x}_n = \\overline{x}_{n-1} + \\dfrac{x_n - \\overline{x}_{n-1}}{n}$\n",
    "    - $M_{2,n} = M_{2,n-1} + (x_n - \\overline{x}_{n-1})(x_n - \\overline{x}_n)$\n",
    "- E as estat√≠sticas s√£o inicializadas da seguinte forma:\n",
    "    - $\\overline{x}_{0} \\leftarrow 0$\n",
    "    - $M_{2,0} \\leftarrow 0$\n",
    "- Para obter a vari√¢ncia amostral basta usar: $s_n^2 = \\dfrac{M_{2,n}}{n-1}$, para todo $n > 1$\n",
    "- De brinde, obtemos um preditor robusto para a m√©dia ü§ì\n",
    "\n",
    "\n",
    "Percentil:\n",
    "\n",
    "- Mantemos dois buffers\n",
    "   - Um com os dados na ordem em que chegam\n",
    "   - Outro com os dados ordenados: o custo de inser√ß√£o de um novo ponto em um vetor j√° ordenado √© $O(\\log n)$\n",
    "   - A remo√ß√£o de um valor no buffer ordenado √© $O(n)$. No buffer n√£o-ordenado √© $O(1)$\n",
    "   - O c√°lculo do percentil usa o buffer ordenado\n",
    "   \n",
    "No fim das contas, sempre buscamos que cada atualiza√ß√£o em uma m√©trica ou modelo de aprendizado tenha um custo constante ($O(1)$). Se isso n√£o for poss√≠vel, ent√£o um custo sub-linear √© o objetivo!\n",
    "\n",
    "---\n",
    "\n",
    "Antes de prosseguirmos, vou mostrar mais uma aplica√ß√£o legal de m√©tricas incrementais, com requintes de processamento distribuido.\n",
    "\n",
    "**Situa√ß√£o hipot√©tica:**\n",
    "\n",
    "E se estiv√©ssemos calculando estat√≠sticas de alguma coisa, mas a coleta era feita de forma separada? Por exemplo, estamos calculando a vari√¢ncia de alguma coisa a n√≠vel estadual, mas a coleta √© feita por munic√≠pio?\n",
    "\n",
    "(Eu sou paranaense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39670.63602877245, 250112.88479177756)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_ca = [rng.gauss(1500, 200) for _ in range(15000)]\n",
    "dados_lndrn = [rng.gauss(2500, 500) for _ in range(600000)]\n",
    "\n",
    "np.var(dados_ca), np.var(dados_lndrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se quisermos calcular a vari√¢ncia (ou m√©dia) total de todos os munic√≠pios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_parana = []\n",
    "\n",
    "# dados_parana.extend(dados_abati√°)\n",
    "# ...\n",
    "dados_parana.extend(dados_ca)\n",
    "# ...\n",
    "dados_parana.extend(dados_lndrn)\n",
    "# ...\n",
    "# dados_parana.extend(dados_xambr√™)\n",
    "\n",
    "len(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268873.83428214735"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2475.850834856662"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dados_parana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√≥s j√° sabemos como fazer esse mesmo processo de forma incremental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estou considerando que todos os dados foram coletados, mas poderia usar o padr√£o, ddof=1\n",
    "var_ca = stats.Var(ddof=0)\n",
    "var_lndrn = stats.Var(ddof=0)\n",
    "\n",
    "for p in dados_ca:\n",
    "    var_ca.update(p)\n",
    "    \n",
    "for p in dados_lndrn:\n",
    "    var_lndrn.update(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39670.63602877236, 250112.88479177424)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.get(), var_lndrn.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posso usar `stats.Mean` para obter a m√©dia. Mas se lembrarmos bem, o algoritmo de Welford tem um preditor de m√©dia \"l√° no meio\", n√£o tem?\n",
    "\n",
    "Voil√†!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1498.2274459163768, 1498.227445916374)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.mean.get(), np.mean(dados_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vem a parte mais legal üôÉ\n",
    "\n",
    "Como obtemos as estat√≠sticas para o estado inteiro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268873.83428214834, 268873.83428214735)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imagine que temos um for somando as estat√≠sticas de todos os estados\n",
    "\n",
    "var_parana = var_ca + var_lndrn  # + os outros municipios\n",
    "\n",
    "var_parana.get(), np.var(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2475.8508348567498, 2475.850834856662)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_parana.mean.get(), np.mean(dados_parana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se a bela e formosa cidade de C√¢ndido de Abreu tivesse sido esquecida? Os dados tivessem sido perdidos, sei l√°...\n",
    "\n",
    "(quando eu era crian√ßa, minha cidade nem aparecia nos mapas impressos do Paran√°, vai saber...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ca_backup = var_parana - var_lndrn  # - os outros municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39670.63602877236, 39670.63602878291)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.get(), var_ca_backup.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1498.2274459163768, 1498.2274459163825)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.mean.get(), var_ca_backup.mean.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No fim das contas, sempre existe um trade-off entre mem√≥ria e tempo de processamento (e a quantidade de \"passadas\" nos dados) e a precis√£o dos resultados obtidos. Muitos dos algor√≠tmos de online learning incluem um par√¢metro ($\\delta$) que indica a porcentagem de \"certeza\" que voc√™ deseja ter nos seus resultados. Em geral, quanto mais certeza, mais tempo leva para tomar as decis√µes.\n",
    "\n",
    "\n",
    "# 4. Por que usar dicion√°rios (ou, por que usar uma representa√ß√£o esparsa)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Como avaliar um modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Exemplos de algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Classifica√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Regress√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Expert stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Pipelines e pr√©-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Exemplo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
