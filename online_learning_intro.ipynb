{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdu√ß√£o (n√£o-extensiva) a Online Learning\n",
    "\n",
    "\n",
    "**Saulo Martiello Mastelini** (mastelini@usp.br)\n",
    "\n",
    "Outras redes:\n",
    "\n",
    "- [Github](https://github.com/smastelini)\n",
    "- [Linkedin](https://www.linkedin.com/in/smastelini/) (eu deveria, mas n√£o atualizo frequentemente -- para ser sincero, est√° muito desatualizado)\n",
    "- [ResearchGate](https://www.researchgate.net/profile/Saulo-Mastelini)\n",
    "\n",
    "MBA em Ci√™ncia de Dados<br>\n",
    "Universidade de S√£o Paulo, S√£o Carlos, Brasil<br>\n",
    "Copyright (c) 2021\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer**\n",
    "\n",
    "Como o t√≠tulo j√° diz, essa n√£o √©, de forma alguma, uma introdu√ß√£o extensiva ao tema. √â apenas a minha humilde tentativa de dar um panorama geral de d√©cadas de pesquisa em uma √°rea que est√° em constante expans√£o e inova√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Sum√°rio\n",
    "1. Online learning? Why?\n",
    "2. Batch vs. Online\n",
    "3. Estruturas necess√°rias: exemplo\n",
    "    - Mean\n",
    "    - Var\n",
    "    - Quantile\n",
    "4. Por que usar dicion√°rios?\n",
    "    - Exemplos com dados faltantes\n",
    "5. Como avaliar um modelo?\n",
    "    - `progressive_val_score`\n",
    "    - label delay\n",
    "6. Exemplos de algoritmos\n",
    "    1. Classifica√ß√£o\n",
    "        1. Logistic regression\n",
    "        2. Hoeffding Tree\n",
    "        3. Naive Bayes\n",
    "        4. Adaptive Random Forest\n",
    "        5. Streaming Random Patches\n",
    "    2. Regress√£o\n",
    "        1. Linear Regression\n",
    "        2. Hoeffding Tree\n",
    "        3. Stochastic Gradient Trees\n",
    "        4. AMRules\n",
    "        5. Adaptive Random Forest\n",
    "        6. Streaming Random Forest\n",
    "    3. Clustering\n",
    "        1. k-Means\n",
    "        2. CluStream\n",
    "        3. DenStream\n",
    "        4. DBSTREAM\n",
    "    4. Anomaly detection\n",
    "        1. Half-space Trees\n",
    "7. Expert module\n",
    "8. Pipelines e pr√©-processamento\n",
    "    - Encoding\n",
    "    - Scaling\n",
    "    - Filtragem e Sele√ß√£o\n",
    "    - Aritm√©tica com Pipelines\n",
    "    - Visualizando as coisas\n",
    "9. Exemplo completo\n",
    "    - processamento em tempo real\n",
    "    - inspe√ß√£o de modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Online Learning? Why?\n",
    "\n",
    "Por que algu√©m deveria se preocupar em atualizar modelos a todo tempo? N√£o √© s√≥ treinar e sair usando?\n",
    "\n",
    "R: sim! Em grande parte dos casos isso √© verdade.\n",
    "\n",
    "Mas imagine que:\n",
    "\n",
    "- A quantidade de dados produzidas √© enorme\n",
    "- N√£o √© poss√≠vel armazenar tudo\n",
    "- Existe limita√ß√£o no poder computacional para treinamento dos modelos\n",
    "    - processador\n",
    "    - mem√≥ria\n",
    "    - bateria\n",
    "- Os dados s√£o n√£o-estacion√°rios e/ou evoluem com o tempo\n",
    "\n",
    "Nesses casos, posso usar aprendizado de m√°quina tradicional? R: sim!!\n",
    "\n",
    "√â poss√≠vel usar aprendizado de m√°quina tradicional se:\n",
    "- Os dados s√£o estacion√°rios (uma amostra representativa dos dados √© suficiente)\n",
    "\n",
    "ou\n",
    "\n",
    "- A velocidade de produ√ß√£o dos dados n√£o √© t√£o alta (batch-incremental e os recursos computacionais s√£o suficientes\n",
    "\n",
    "## 1.1 Batch-incremental\n",
    "\n",
    "\n",
    "Um modelo tradicional de aprendizado de m√°quina √© re-treinado de tempos em tempos. Para tal, uma janela para treinamento precisa ser definida.\n",
    "\n",
    "Tipos de janelamento dos dados:\n",
    "\n",
    "\n",
    "<img src=\"time_windows.png\">\n",
    "\n",
    "**Fonte:** Adaptado de:\n",
    "\n",
    "> Carnein, M. and Trautmann, H., 2019. Optimizing data stream representation: An extensive survey on stream clustering algorithms. Business & Information Systems Engineering, 61(3), pp.277-297.\n",
    "\n",
    "- *Landmarks* s√£o a escolha mais comum em estrat√©gias batch-incremental. √â preciso definir o tamanho da janela de forma adequada.\n",
    "    - O modelo pode ficar defasado se a janela for muito grande \n",
    "    - Ou o modelo pode n√£o capturar os padr√µes se a janela for muito pequena\n",
    "    - Concept-drift √© um problema e tanto\n",
    "    \n",
    "**Aten√ß√£o**: batch-incremental != mini-batch.\n",
    "Redes neurais podem ser treinadas de forma incremental ou progressiva. No entanto, quest√µes como \"esquecimento catastr√≥fico\" s√£o problem√°ticas. Esse e outros tipos de desafios s√£o tratados na √°rea de pesquisa chamada **continual learning**.\n",
    "\n",
    "## 1.2 Importante lembrar\n",
    "\n",
    "Data streams n√£o s√£o, necessariamente, s√©ries temporais! ü§Ø\n",
    "\n",
    "Mas qual √© a diferen√ßa, ent√£o?\n",
    "\n",
    "Basicamente, em streams n√£o necessariamente temos depend√™ncias temporais expl√≠citas como em s√©ries temporais. Por exemplo: rede de sensores.\n",
    "\n",
    "Os dados chegam temporalmente organizados, mas cada sensor tem uma taxa de transmiss√£o espec√≠fica, ou um delay espec√≠fico. Alguns sensores pode falhar... outros serem adicionados. E assim por diante.\n",
    "\n",
    "A ordem de chegada n√£o importa... tanto, mas importa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Batch vs. Online\n",
    "\n",
    "Uma boa introdu√ß√£o acerca da \"migra√ß√£o\" de batch para online est√° dispon√≠vel no [site](https://riverml.xyz/latest/examples/batch-to-online/) do River. Aqui eu s√≥ quero dar uma vis√£o bem geral das diferen√ßas. Entraremos em mais detalhes posteriormente nas min√∫cias de avalia√ß√£o de modelos em Online Learning.\n",
    "\n",
    "\n",
    "Uma poss√≠vel valida√ß√£o de um modelo tradicional de aprendizado de m√°quina poderia ter essa \"cara\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia m√©dia: 0.9045751633986928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = load_wine()\n",
    "\n",
    "X, y = data.data, data.target\n",
    "kf = KFold(shuffle=True, random_state=8, n_splits=10)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_tr, X_ts = X[train], X[test]\n",
    "    y_tr, y_ts = y[train], y[test]\n",
    "    \n",
    "    dt  = DecisionTreeClassifier(max_depth=5, random_state=93)\n",
    "    dt.fit(X_tr, y_tr)\n",
    "    \n",
    "    accs.append(accuracy_score(y_ts, dt.predict(X_ts)))\n",
    "\n",
    "print(f\"Acur√°cia m√©dia: {sum(accs) / len(accs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparem que todo o conjunto de dados est√° dispon√≠vel e carregado em mem√≥ria. O algoritmo de √°rvore de decis√£o pode percorrer os dados de treino quantas vezes forem necess√°rias. Os dados de teste (valida√ß√£o, no nosso caso) nunca s√£o utilizados para treino.\n",
    "\n",
    "No fim das contas, usar√≠amos o conjunto completo para treinar um modelo final (supondo que j√° encontramos um conjunto adequado de hiper-par√¢metros). Uma vez treinado, esse modelo seria utilizado para fazer predi√ß√µes para novas amostras (de vinhos, nesse caso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 0.9269662921348315\n"
     ]
    }
   ],
   "source": [
    "from river import metrics\n",
    "from river import stream\n",
    "from river import tree\n",
    "\n",
    "\n",
    "acc = metrics.Accuracy()\n",
    "ht = tree.HoeffdingTreeClassifier(max_depth=5, grace_period=20)\n",
    "\n",
    "for x, y in stream.iter_sklearn_dataset(load_wine()):\n",
    "    # M√©trica atualizada antes do treinamento\n",
    "    acc.update(y, ht.predict_one(x))\n",
    "    # Modelo treinado amostra-a-amostra\n",
    "    ht.learn_one(x, y)\n",
    "\n",
    "print(f\"Acur√°cia: {acc.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, estamos percorrendo cada exemplo do conjunto de dados de forma sequencial. Os exemplos poderiam ser carregados diretamente do disco, de algum webservice, ou de onde sua imagina√ß√£o te levar, sem a necessidade de salvar em mem√≥ria nada.\n",
    "\n",
    "Cada amostra √© primeiramente utilizada para teste e depois passada para o modelo. Tudo √© atualizado uma amostra por vez. Notem que n√£o podemos comparar diretamente os desempenhos obtidos porque a estrat√©gia de avalia√ß√£o foi diferente nos dois casos.\n",
    "\n",
    "Poder√≠amos ainda (pseudo) embaralhar os dados antes de passar para o modelo, se temos plena confian√ßa que os dados s√£o estacion√°rios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estruturas necess√°rias: exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from river import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado esse choque inicial, vamos prosseguir com calma e primeiramente pensar em alguns aspectos importantes antes de vermos os algoritmos de aprendizado de m√°quina online.\n",
    "\n",
    "## 3.1. Um exemplo, para aquecimento cerebral\n",
    "\n",
    "Vamos supor que queremos calcular estat√≠sticas para dados que chegam a todo momento:\n",
    "\n",
    "- M√©dia\n",
    "- Vari√¢ncia\n",
    "- ...\n",
    "\n",
    "Hora de simular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 15.2 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valores = []\n",
    "stds_batch = []\n",
    "\n",
    "for _ in range(50000):\n",
    "    v = rng.gauss(5, 3)\n",
    "    valores.append(v)\n",
    "    \n",
    "    stds_batch.append(np.std(valores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padr√£o o numpy calcula o desvio padr√£o populacional! Para usar a vers√£o amostral precisamos passar `ddof=1` como par√¢metro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stds_incr = []\n",
    "var = stats.Var(ddof=0)\n",
    "\n",
    "for _ in range(50000):\n",
    "    v = rng.gauss(5, 3)\n",
    "    var.update(v)\n",
    "    stds_incr.append(var.get() ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√° que d√° alguma diferen√ßa? E ser√° que funciona?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.301100448023121e-10, 8.602200896046241e-15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_erros = 0\n",
    "\n",
    "for batch, incr in zip(stds_batch, stds_incr):\n",
    "    s_erros += (batch - incr)\n",
    "\n",
    "s_erros, s_erros / len(stds_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... parece convincente. Mas e se o cen√°rio fosse diferente? Se ao inv√©s de calcularmos o desvio padr√£o e irmos aumentando a quantidade de dados, quisessemos descobrir um percentil das √∫ltimas `N` amostras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)\n",
    "\n",
    "tam = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 103 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "buffer = []\n",
    "percs75_batch = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    v = rng.uniform(-100, 100)\n",
    "    buffer.append(v)\n",
    "    if len(buffer) <= tam:\n",
    "        continue\n",
    "        \n",
    "    percs75_batch.append(np.quantile(buffer, q=0.75))\n",
    "    buffer.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos fazer um pouco melhor que isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 s, sys: 3.98 ms, total: 6.27 s\n",
      "Wall time: 6.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "qtl = stats.RollingQuantile(window_size=tam, q=0.75)\n",
    "percs75_incr = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    v = rng.uniform(-100, 100)\n",
    "    qtl.update(v)\n",
    "    if len(qtl) <= tam:\n",
    "        continue\n",
    "        \n",
    "    percs75_incr.append(qtl.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_erros = 0\n",
    "\n",
    "for batch, incr in zip(percs75_batch, percs75_incr):\n",
    "    s_erros += (batch - incr)\n",
    "\n",
    "s_erros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero t√™-los convencido! O [m√≥dulo](https://riverml.xyz/dev/api/overview/#stats) `stats` do River tem v√°rias fun√ß√µes √∫teis para sumariza√ß√£o de dados de forma incremental. Vale a pena checar! üßê\n",
    "\n",
    "A raz√£o pela qual eu quis mostrar tudo isso √© porque v√°rios desses algoritmos s√£o os \"tijolos\" que comp√µem os algoritmos de aprendizado de m√°quina. Uma receita breve para online learning:\n",
    "\n",
    "- A jun√ß√£o de m√©tricas estat√≠sticas incrementais\n",
    "- Algumas grandezas probabil√≠sticas\n",
    "- Algumas teorias de aprendizado de m√°quina que s√£o gen√©ricas e n√£o limitadas ao cen√°rio in-batch\n",
    "- Gradiente descendente\n",
    "- *otras cositas*\n",
    "\n",
    "Com isso tudo √© poss√≠vel formar boa parte dos algoritmos de aprendizado incremental. Mas isso √© extremamente gen√©rico de se dizer, n√£o √©? Bom, no fim das contas, o aprendizado de m√°quina tradicional tamb√©m \"se resume\" a algumas coisas pontuais, mas que s√£o extremamente abrangentes por si s√≥.\n",
    "\n",
    "Que tal entendermos um pouco de como os exemplos anteriores funcionam e por que eles funcionam?\n",
    "\n",
    "## 3.2. Uma (extremamente) breve reflex√£o sobre complexidade dos algoritmos\n",
    "\n",
    "Quanto custa para calcular a vari√¢ncia (no caso, desvio padr√£o) e o percentil nos exemplos anteriores?\n",
    "\n",
    "**Modo batch**\n",
    "\n",
    "Vari√¢ncia:  $\\dfrac{\\sum_i^N (x_i - \\bar{x})}{N - 1}$\n",
    "\n",
    "- M√©dia √© calculada com o custo $O(n)$ -> todos os elementos devem ser somados e divididos pelo total de observa√ß√µes\n",
    "- Com a m√©dia em m√£os, precisamos calcular o desvio de cada elemento para a m√©dia e somar tais desvios: $O(n)$\n",
    "- No fim das contas, o custo final √© $O(n)$ (na nota√ß√£o assint√≥tica), mas tivemos que percorrer todos os dados duas vezes (e, consequentemente, armazen√°-los).\n",
    "- Esse algoritmo tamb√©m apresenta problemas de estabilidade, quando o n√∫mero de observa√ß√µes √© muito grande. Pode gerar erros num√©ricos de aproxima√ß√£o.\n",
    "\n",
    "Percentil:\n",
    "\n",
    "- Pegue um exemplo novo e remova o mais antigo\n",
    "- Ordene os dados: algo em torno de $O(n\\log n)$ (n √© o tamanho do buffer)\n",
    "- Encontre a posi√ß√£o correta, interpole e retorne\n",
    "\n",
    "Se esse processo √© repetido v√°rias e v√°rias vezes...\n",
    "\n",
    "**Modo incremental**\n",
    "\n",
    "\n",
    "Vari√¢ncia (algoritmo de Welford):\n",
    "\n",
    "- Precisamos de algumas vari√°veis:\n",
    "    - $n$: n√∫mero de observa√ß√µes\n",
    "    - $\\overline{x}_n$: a m√©dia da amostral, ap√≥s $n$ observa√ß√µes\n",
    "    - $M_{2, n}$: estat√≠stica de segunda ordem que gerar√° a vari√¢ncia\n",
    "- As atualiza√ß√µes das estat√≠sticas se d√£o na seguinte forma:\n",
    "    - $\\overline{x}_n = \\overline{x}_{n-1} + \\dfrac{x_n - \\overline{x}_{n-1}}{n}$\n",
    "    - $M_{2,n} = M_{2,n-1} + (x_n - \\overline{x}_{n-1})(x_n - \\overline{x}_n)$\n",
    "- E as estat√≠sticas s√£o inicializadas da seguinte forma:\n",
    "    - $\\overline{x}_{0} \\leftarrow 0$\n",
    "    - $M_{2,0} \\leftarrow 0$\n",
    "- Para obter a vari√¢ncia amostral basta usar: $s_n^2 = \\dfrac{M_{2,n}}{n-1}$, para todo $n > 1$\n",
    "- De brinde, obtemos um preditor robusto para a m√©dia ü§ì\n",
    "\n",
    "\n",
    "Percentil:\n",
    "\n",
    "- Mantemos dois buffers\n",
    "   - Um com os dados na ordem em que chegam\n",
    "   - Outro com os dados ordenados: o custo de inser√ß√£o de um novo ponto em um vetor j√° ordenado √© $O(\\log n)$\n",
    "   - A remo√ß√£o de um valor no buffer ordenado √© $O(n)$. No buffer n√£o-ordenado √© $O(1)$\n",
    "   - O c√°lculo do percentil usa o buffer ordenado\n",
    "   \n",
    "No fim das contas, sempre buscamos que cada atualiza√ß√£o em uma m√©trica ou modelo de aprendizado tenha um custo constante ($O(1)$). Se isso n√£o for poss√≠vel, ent√£o um custo sub-linear √© o objetivo!\n",
    "\n",
    "---\n",
    "\n",
    "Antes de prosseguirmos, vou mostrar mais uma aplica√ß√£o legal de m√©tricas incrementais, com requintes de processamento distribuido.\n",
    "\n",
    "**Situa√ß√£o hipot√©tica:**\n",
    "\n",
    "E se estiv√©ssemos calculando estat√≠sticas de alguma coisa, mas a coleta era feita de forma separada? Por exemplo, estamos calculando a vari√¢ncia de alguma coisa a n√≠vel estadual, mas a coleta √© feita por munic√≠pio?\n",
    "\n",
    "(Eu sou paranaense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39496.429786146546, 249442.43568603016)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_ca = [rng.gauss(1500, 200) for _ in range(15000)]\n",
    "dados_lndrn = [rng.gauss(2500, 500) for _ in range(600000)]\n",
    "\n",
    "np.var(dados_ca), np.var(dados_lndrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se quisermos calcular a vari√¢ncia (ou m√©dia) total de todos os munic√≠pios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_parana = []\n",
    "\n",
    "# dados_parana.extend(dados_abati√°)\n",
    "# ...\n",
    "dados_parana.extend(dados_ca)\n",
    "# ...\n",
    "dados_parana.extend(dados_lndrn)\n",
    "# ...\n",
    "# dados_parana.extend(dados_xambr√™)\n",
    "\n",
    "len(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268085.14104958007"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2475.927394402956"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dados_parana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√≥s j√° sabemos como fazer esse mesmo processo de forma incremental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estou considerando que todos os dados foram coletados, mas poderia usar o padr√£o, ddof=1\n",
    "var_ca = stats.Var(ddof=0)\n",
    "var_lndrn = stats.Var(ddof=0)\n",
    "\n",
    "for p in dados_ca:\n",
    "    var_ca.update(p)\n",
    "    \n",
    "for p in dados_lndrn:\n",
    "    var_lndrn.update(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39496.429786146546, 249442.4356860276)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.get(), var_lndrn.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posso usar `stats.Mean` para obter a m√©dia. Mas se lembrarmos bem, o algoritmo de Welford tem um preditor de m√©dia \"l√° no meio\", n√£o tem?\n",
    "\n",
    "Voil√†!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500.9742744265895, 1500.9742744265982)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.mean.get(), np.mean(dados_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vem a parte mais legal üôÉ\n",
    "\n",
    "Como obtemos as estat√≠sticas para o estado inteiro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268085.1410495726, 268085.14104958007)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imagine que temos um for somando as estat√≠sticas de todos os estados\n",
    "\n",
    "var_parana = var_ca + var_lndrn  # + os outros municipios\n",
    "\n",
    "var_parana.get(), np.var(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2475.927394402848, 2475.927394402956)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_parana.mean.get(), np.mean(dados_parana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se a bela e formosa cidade de C√¢ndido de Abreu tivesse sido esquecida? Os dados tivessem sido perdidos, sei l√°...\n",
    "\n",
    "(quando eu era crian√ßa, minha cidade nem aparecia nos mapas impressos do Paran√°, vai saber...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ca_backup = var_parana - var_lndrn  # - os outros municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39496.429786146546, 39496.42978614286)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.get(), var_ca_backup.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500.9742744265895, 1500.9742744265875)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ca.mean.get(), var_ca_backup.mean.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No fim das contas, sempre existe um trade-off entre mem√≥ria e tempo de processamento (e a quantidade de \"passadas\" nos dados) e a precis√£o dos resultados obtidos. Muitos dos algor√≠tmos de online learning incluem um par√¢metro ($\\delta$) que indica a porcentagem de \"certeza\" que voc√™ deseja ter nos seus resultados. Em geral, quanto mais certeza, mais tempo leva para tomar as decis√µes.\n",
    "\n",
    "\n",
    "# 4. Por que usar dicion√°rios (ou, por que usar uma representa√ß√£o esparsa)?\n",
    "\n",
    "Um as primeiras coisas que podem chamar a aten√ß√£o no River √© o tipo de dados que √© utilizado: dicion√°rios python.\n",
    "\n",
    "- Chave x valor: chaves s√£o √∫nicas\n",
    "- Valores acessados via chave, ao inv√©s de √≠ndice\n",
    "- Dicion√°rios s√£o estruturas naturalmente esparsas\n",
    "- Diferentemente de arrays, vetores, matrizes (e etc.) n√£o possuem uma ordena√ß√£o expl√≠cita\n",
    "- Podem ser extendidos\n",
    "- Podem ter vari√°veis de tipo misto\n",
    "\n",
    "Exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batata': 3,\n",
       " 'carro': 2,\n",
       " 'data': datetime.datetime(2021, 8, 27, 16, 29, 4, 600418),\n",
       " 'sim_ou_n√£o': 'sim'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "x = {\n",
    "    \"batata\": 3,\n",
    "    \"carro\": 2,\n",
    "    \"data\": datetime.now(),\n",
    "    \"sim_ou_n√£o\": \"sim\"\n",
    "}\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batata': 3,\n",
       " 'carro': 2,\n",
       " 'data': datetime.datetime(2021, 8, 27, 16, 29, 4, 600418),\n",
       " 'sim_ou_n√£o': 'sim',\n",
       " 'mais um': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"mais um\"] = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batata': 3, 'carro': 2, 'sim_ou_n√£o': 'sim', 'mais um': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x[\"data\"]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse tipo de estrutura √© muito parecida com o popular formato JSON (para transfer√™ncia de dados)!\n",
    "\n",
    "Que tal compararmos com o que √© mais usual?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "        1.065e+03]),\n",
       " ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_wine()\n",
    "\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X[0, :], data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array(['class_0', 'class_1', 'class_2'], dtype='<U7'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos colocar o sklearn √† prova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((176, 13), (2, 13))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, y_tr = X[:-2, :], y[:-2]\n",
    "X_ts, y_ts = X[-2:, :], y[-2:]\n",
    "\n",
    "X_tr.shape, X_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_tr, y_tr)\n",
    "\n",
    "nb.predict(X_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, e se uma feature estivesse faltando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operands could not be broadcast together with shapes (2,12) (13,) \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nb.predict(X_ts[:, 1:])\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em Online Learning n√≥s n√£o dever√≠amos ficar nos preocupando com \"coisa pouca\" assim. Brincadeiras a parte, em um cen√°rio de aprendizado online, sensores podem falhar, novos dados podem surgir, entre muitas outras coisas que podem alterar os dados de entrada. Precisamos de uma representa√ß√£o e modelos robustos quanto a isso!\n",
    "\n",
    "Com o River, a vasta maioria dos modelos est√° pronta para lidar com esse tipo de problema! üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import naive_bayes\n",
    "\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "dataset = stream.iter_sklearn_dataset(load_wine())\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "# Chance de feature ser ignorada\n",
    "del_chance = 0.2\n",
    "\n",
    "n_linhas_incompletas = 0\n",
    "for i, (x, y) in enumerate(dataset):\n",
    "    if i == 176:\n",
    "        break\n",
    "    \n",
    "    x_copy = x.copy()\n",
    "    aux = 0\n",
    "    for xi in x:\n",
    "        if rng.random() <= del_chance:\n",
    "            del x_copy[xi]\n",
    "            aux = 1\n",
    "        \n",
    "        # Atualiza o n√∫mero de linhas incompletas\n",
    "        n_linhas_incompletas += aux\n",
    "    \n",
    "    gnb.learn_one(x_copy, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `naive_bayes.GaussianNB` not found.\n"
     ]
    }
   ],
   "source": [
    "?naive_bayes.GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alcohol': 13.17,\n",
       "  'malic_acid': 2.59,\n",
       "  'ash': 2.37,\n",
       "  'alcalinity_of_ash': 20.0,\n",
       "  'magnesium': 120.0,\n",
       "  'total_phenols': 1.65,\n",
       "  'flavanoids': 0.68,\n",
       "  'nonflavanoid_phenols': 0.53,\n",
       "  'proanthocyanins': 1.46,\n",
       "  'color_intensity': 9.3,\n",
       "  'hue': 0.6,\n",
       "  'od280/od315_of_diluted_wines': 1.62,\n",
       "  'proline': 840.0},\n",
       " 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.2901730526821133e-23, 1: 4.523692607178262e-14, 2: 0.9999999999999538}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict_proba_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos bagun√ßar a √∫ltima amostra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(dataset)\n",
    "list(x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou tirar um c√≥pia do `x` e remover umas coisas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alcohol': 14.13,\n",
       " 'ash': 2.74,\n",
       " 'alcalinity_of_ash': 24.5,\n",
       " 'magnesium': 96.0,\n",
       " 'total_phenols': 2.05,\n",
       " 'nonflavanoid_phenols': 0.56,\n",
       " 'proanthocyanins': 1.35,\n",
       " 'color_intensity': 9.2,\n",
       " 'od280/od315_of_diluted_wines': 1.6,\n",
       " 'proline': 560.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_copy = x.copy()\n",
    "\n",
    "del x_copy[\"malic_acid\"]\n",
    "del x_copy[\"hue\"]\n",
    "del x_copy[\"flavanoids\"]\n",
    "\n",
    "x_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√° que o nosso modelo d√° conta do recado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 7.394823717897321e-13, 1: 8.511456030879924e-13, 2: 0.9999999999984084},\n",
       " 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict_proba_one(x_copy), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se ao inv√©s de diminuir o n√∫mero de features aumentasse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alcohol': 14.13,\n",
       " 'malic_acid': 4.1,\n",
       " 'ash': 2.74,\n",
       " 'alcalinity_of_ash': 24.5,\n",
       " 'magnesium': 96.0,\n",
       " 'total_phenols': 2.05,\n",
       " 'flavanoids': 0.76,\n",
       " 'nonflavanoid_phenols': 0.56,\n",
       " 'proanthocyanins': 1.35,\n",
       " 'color_intensity': 9.2,\n",
       " 'hue': 0.61,\n",
       " 'od280/od315_of_diluted_wines': 1.6,\n",
       " 'proline': 560.0,\n",
       " 'primeira extra': 7.89,\n",
       " 'segunda extra': 2}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"primeira extra\"] = 7.89\n",
    "x[\"segunda extra\"] = 2\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.learn_one(x, y)\n",
    "\n",
    "gnb.predict_one({\"primeira extra\": 7.8, \"segunda extra\": 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([59, 71, 48]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada tipo de modelo implementa estrat√©gias diferentes para lidar com atributos emergentes ou faltantes!\n",
    "\n",
    "No nosso exemplo, \"1\" era a classe majorit√°ria. Essa foi a escolha feita pelo GaussianNB, j√° que h√° pouca informa√ß√£o acerca dos dois atributos extra que adicionamos. Mas eles j√° fazem parte do modelo e ser√£o atualizados caso novas observa√ß√µes cheguem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(functools.partial(<class 'collections.defaultdict'>, <class 'river.proba.gaussian.Gaussian'>),\n",
       "            {0: defaultdict(river.proba.gaussian.Gaussian,\n",
       "                         {'alcohol': ùí©(Œº=13.751, œÉ=0.434),\n",
       "                          'ash': ùí©(Œº=2.473, œÉ=0.234),\n",
       "                          'alcalinity_of_ash': ùí©(Œº=16.896, œÉ=2.671),\n",
       "                          'magnesium': ùí©(Œº=107.082, œÉ=10.720),\n",
       "                          'total_phenols': ùí©(Œº=2.811, œÉ=0.286),\n",
       "                          'flavanoids': ùí©(Œº=2.955, œÉ=0.367),\n",
       "                          'proanthocyanins': ùí©(Œº=1.881, œÉ=0.399),\n",
       "                          'hue': ùí©(Œº=1.077, œÉ=0.119),\n",
       "                          'od280/od315_of_diluted_wines': ùí©(Œº=3.131, œÉ=0.348),\n",
       "                          'malic_acid': ùí©(Œº=1.982, œÉ=0.661),\n",
       "                          'nonflavanoid_phenols': ùí©(Œº=0.288, œÉ=0.071),\n",
       "                          'color_intensity': ùí©(Œº=5.443, œÉ=1.342),\n",
       "                          'proline': ùí©(Œº=1114.224, œÉ=228.521),\n",
       "                          'primeira extra': ùí©(Œº=0.000, œÉ=0.000),\n",
       "                          'segunda extra': ùí©(Œº=0.000, œÉ=0.000)}),\n",
       "             1: defaultdict(river.proba.gaussian.Gaussian,\n",
       "                         {'alcohol': ùí©(Œº=12.261, œÉ=0.549),\n",
       "                          'ash': ùí©(Œº=2.228, œÉ=0.334),\n",
       "                          'alcalinity_of_ash': ùí©(Œº=20.347, œÉ=3.468),\n",
       "                          'magnesium': ùí©(Œº=94.476, œÉ=16.685),\n",
       "                          'flavanoids': ùí©(Œº=2.040, œÉ=0.711),\n",
       "                          'nonflavanoid_phenols': ùí©(Œº=0.371, œÉ=0.130),\n",
       "                          'color_intensity': ùí©(Œº=3.128, œÉ=0.905),\n",
       "                          'hue': ùí©(Œº=1.065, œÉ=0.184),\n",
       "                          'od280/od315_of_diluted_wines': ùí©(Œº=2.751, œÉ=0.508),\n",
       "                          'malic_acid': ùí©(Œº=1.995, œÉ=1.083),\n",
       "                          'total_phenols': ùí©(Œº=2.288, œÉ=0.548),\n",
       "                          'proanthocyanins': ùí©(Œº=1.687, œÉ=0.617),\n",
       "                          'proline': ùí©(Œº=523.582, œÉ=169.681),\n",
       "                          'primeira extra': ùí©(Œº=0.000, œÉ=0.000),\n",
       "                          'segunda extra': ùí©(Œº=0.000, œÉ=0.000)}),\n",
       "             2: defaultdict(river.proba.gaussian.Gaussian,\n",
       "                         {'alcohol': ùí©(Œº=13.302, œÉ=0.601),\n",
       "                          'malic_acid': ùí©(Œº=3.481, œÉ=1.141),\n",
       "                          'alcalinity_of_ash': ùí©(Œº=22.022, œÉ=2.378),\n",
       "                          'magnesium': ùí©(Œº=97.844, œÉ=9.707),\n",
       "                          'nonflavanoid_phenols': ùí©(Œº=0.455, œÉ=0.134),\n",
       "                          'proanthocyanins': ùí©(Œº=1.192, œÉ=0.407),\n",
       "                          'color_intensity': ùí©(Œº=7.399, œÉ=2.281),\n",
       "                          'hue': ùí©(Œº=0.677, œÉ=0.101),\n",
       "                          'od280/od315_of_diluted_wines': ùí©(Œº=1.680, œÉ=0.256),\n",
       "                          'proline': ùí©(Œº=612.766, œÉ=105.257),\n",
       "                          'ash': ùí©(Œº=2.494, œÉ=0.198),\n",
       "                          'total_phenols': ùí©(Œº=1.770, œÉ=0.342),\n",
       "                          'flavanoids': ùí©(Œº=0.762, œÉ=0.256),\n",
       "                          'primeira extra': ùí©(Œº=7.890, œÉ=0.000),\n",
       "                          'segunda extra': ùí©(Œº=2.000, œÉ=0.000)})})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Como avaliar um modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Exemplos de algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Classifica√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Regress√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Expert stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Pipelines e pr√©-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Exemplo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
