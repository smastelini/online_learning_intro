{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdu√ß√£o (n√£o-extensiva) a Online Learning\n",
    "\n",
    "\n",
    "**Saulo Martiello Mastelini** (mastelini@usp.br)\n",
    "\n",
    "Outras redes:\n",
    "\n",
    "- [Github](https://github.com/smastelini)\n",
    "- [Linkedin](https://www.linkedin.com/in/smastelini/) (eu deveria, mas n√£o atualizo frequentemente -- para ser sincero, est√° bem desatualizado)\n",
    "- [ResearchGate](https://www.researchgate.net/profile/Saulo-Mastelini)\n",
    "\n",
    "MBA em Ci√™ncia de Dados<br>\n",
    "Universidade de S√£o Paulo, S√£o Carlos, Brasil<br>\n",
    "Copyright (c) 2021\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer**\n",
    "\n",
    "Como o t√≠tulo j√° diz, essa n√£o √©, de forma alguma, uma introdu√ß√£o extensiva ao tema. √â apenas a minha humilde tentativa de dar um panorama geral de d√©cadas de pesquisa em uma √°rea que est√° em constante expans√£o e inova√ß√£o.\n",
    "\n",
    "Feliz ou infelizmente, **todo processo de aprendizado leva tempo**. Assim, n√£o ser√° poss√≠vel aprofundar em toda uma √°rea de pesquisa de d√©cadas em apenas algumas horas.\n",
    "\n",
    "Pretendo me inspirar na busca em estruturas de √°rvores (teoria dos grafos) para guiar nosso estudo. Vou mostrar tr√™s op√ß√µes (a √∫ltima customizada ao meu gosto), das quais as duas primeiras eu quero evitar:\n",
    "\n",
    "1. **Busca em largura:** corremos o risco de n√£o abordar tudo o que h√° de mais popular e, ainda por cima, sermos t√£o superficiais que os conte√∫dos seriam de pouca valia.\n",
    "2. **Busca em profundidade:** aqui o risco √© querer focar muito em um min√∫cias ou em um ponto espec√≠fico e acabar n√£o tendo um panorama geral das coisas.\n",
    "3. **Busca em profundidade limitada** (e adaptativa) **:** Nos aprofundaremos um pouco em cada t√≥pico, n√£o muito, mas se quiserem, podemos nos aprofundar mais. Cabe a voc√™s pedirem! No entanto, me reservo ao direito de arbitrar o quanto devemos insistir num assunto durante nosso escasso tempo: buscarei balancear interesses individuais e o coletivo, bem como julgar o que pode ou n√£o ajudar no estudo individual de cada um.\n",
    "\n",
    "---\n",
    "\n",
    "**Ponto de partida para aprofundamento**\n",
    "\n",
    "Para quem quiser se aprofundar mais nos assuntos que eu vou apresentar hoje, eu sugiro os seguintes recursos:\n",
    "\n",
    "- [Livro do MOA](https://moa.cms.waikato.ac.nz/book-html/): um livro de acesso aberto que abrange v√°rios t√≥picos ligados a stream learning\n",
    "- [Documenta√ß√£o do River](https://riverml.xyz/dev/): conta com v√°rios exemplos e tutoriais, al√©m de referenciais pr√°ticos e te√≥ricos! Est√° sempre sendo expandida, corrigida e atualizada.\n",
    "\n",
    "Quem tiver alguma d√∫vida espec√≠fica que a documenta√ß√£o n√£o possa suprir pode sempre abrir uma \"*Discussion*\" no Github. √â s√≥ ir no [reposit√≥rio do Github do River](https://github.com/online-ml/river) e clicar na aba de discuss√µes. Algu√©m da equipe de desenvolvimento ou da comunidade de usu√°rios do River com grande certeza estar√° disposto a ajudar!\n",
    "\n",
    "Contribui√ß√µes s√£o bem vindas! O River √© um projeto *Open Source* constru√≠do pela comunidade. Mesmo que algu√©m possa n√£o ter conhecimento t√©cnico dos algoritmos, sempre √© poss√≠vel ajudar! Corre√ß√µes e expans√µes na documenta√ß√£o, por exemplo, s√£o formas de ajudar! Muitas vezes apontar erros ou bugs (atrav√©s de *issues*) j√° √© de grande ajuda! üòÅ\n",
    "\n",
    "---\n",
    "\n",
    "**Sobre o River**\n",
    "\n",
    "O River √© um projeto open source para online learning e stream mining. Ele surgiu a partir da fus√£o de duas ferramentas (tamb√©m open-source):\n",
    "\n",
    "- creme\n",
    "- scikit-multiflow\n",
    "\n",
    "Ambos os pacotes Python abordavam o mesmo tema, mas com enfoques espec√≠ficos. Ap√≥s um longo tempo de planejamento e conversas, os mantenedores e times de desenvolvimento dos dois pacotes uniram for√ßas e lan√ßaram o River. O novo pacote √© o produto dos anos de li√ß√µes aprendidas no desenvolvimento das ferramentas predecessoras.\n",
    "\n",
    "O River reune o que havia de melhor `creme` e `scikit-multiflow` (que foram descontinuados) e supera pontos fracos que existiam nos projetos anteriores. A nova ferramenta √© voltada tanto para o uso no mercado quanto na academia.\n",
    "\n",
    "O River conta com muitos contribuidores, mas a maioria do time de desenvolvimento est√° distribu√≠do entre a Fran√ßa, Nova Zel√¢ndia e Brasil.\n",
    "\n",
    "O artigo da ferramenta no JMLR pode ser acessado [aqui](https://www.jmlr.org/papers/v22/20-1380.html).\n",
    "\n",
    "O site do River √© o: https://riverml.xyz\n",
    "\n",
    "Existe muita demanda e nem tanto tempo üòÖ. Se quiserem checar os planos para o futuro, visitem o nosso [Roadmap](https://www.notion.so/d1e86fcdf21e4deda16eedab2b3361fb?v=503f44740b8b44a99a961aa96e9e46e1).\n",
    "\n",
    "---\n",
    "\n",
    "## Sum√°rio\n",
    "1. Online learning? Why?\n",
    "2. Batch vs. Online\n",
    "3. Estruturas necess√°rias: exemplo\n",
    "    - Mean\n",
    "    - Var\n",
    "    - Quantile\n",
    "4. Por que usar dicion√°rios?\n",
    "    - Exemplos com dados faltantes\n",
    "5. Como avaliar um modelo?\n",
    "    - `progressive_val_score`\n",
    "    - label delay\n",
    "6. Concept drift\n",
    "7. Exemplos de algoritmos\n",
    "    1. Classifica√ß√£o\n",
    "        1. Logistic regression\n",
    "        2. Hoeffding Tree\n",
    "        3. Naive Bayes\n",
    "        4. Adaptive Random Forest\n",
    "        5. Streaming Random Patches\n",
    "    2. Regress√£o\n",
    "        1. Linear Regression\n",
    "        2. **Hoeffding Tree**\n",
    "        3. **AMRules**\n",
    "        4. **Adaptive Random Forest**\n",
    "        5. **Streaming Random Patches**\n",
    "    3. Clustering\n",
    "        1. k-Means\n",
    "    4. Anomaly detection\n",
    "        1. Half-space Trees\n",
    "8. Expert module\n",
    "9. Pipelines e pr√©-processamento\n",
    "    - Encoding\n",
    "    - Scaling\n",
    "    - Filtragem e Sele√ß√£o\n",
    "    - Aritm√©tica com Pipelines\n",
    "    - Visualizando as coisas\n",
    "10. Exemplo completo\n",
    "    - processamento em tempo real\n",
    "    - inspe√ß√£o de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esses s√£o os pacotes que est√£o sendo utilizados nesse notebook\n",
    "# As linhas a seguir podem ser descomentadas para instalar o que for necess√°rio\n",
    "\n",
    "# !pip install numpy\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# Ultima vers√£o lan√ßada\n",
    "# !pip install river\n",
    "\n",
    "# Eu estou usando a vers√£o de desenvolvimento, que pode ser instalada com:\n",
    "#!pip install git+https://github.com/online-ml/river --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Online Learning? Why?\n",
    "\n",
    "Por que algu√©m deveria se preocupar em atualizar modelos a todo tempo? N√£o √© s√≥ treinar e sair usando?\n",
    "\n",
    "R: sim! Em grande parte dos casos isso √© verdade.\n",
    "\n",
    "Mas imagine que:\n",
    "\n",
    "- A quantidade de dados produzidas √© enorme\n",
    "- N√£o √© poss√≠vel armazenar tudo\n",
    "- Existe limita√ß√£o no poder computacional para treinamento dos modelos\n",
    "    - processador\n",
    "    - mem√≥ria\n",
    "    - bateria\n",
    "- Os dados s√£o n√£o-estacion√°rios e/ou evoluem com o tempo\n",
    "\n",
    "Nesses casos, posso usar aprendizado de m√°quina tradicional? R: sim!!\n",
    "\n",
    "√â poss√≠vel usar aprendizado de m√°quina tradicional se:\n",
    "- Os dados s√£o estacion√°rios (uma amostra representativa dos dados √© suficiente)\n",
    "\n",
    "ou\n",
    "\n",
    "- A velocidade de produ√ß√£o dos dados n√£o √© t√£o alta (batch-incremental e os recursos computacionais s√£o suficientes)\n",
    "\n",
    "## 1.1 Batch-incremental\n",
    "\n",
    "\n",
    "Um modelo tradicional de aprendizado de m√°quina √© re-treinado de tempos em tempos. Para tal, uma janela para treinamento precisa ser definida.\n",
    "\n",
    "Tipos de janelamento dos dados:\n",
    "\n",
    "\n",
    "<img src=\"time_windows.png\">\n",
    "\n",
    "**Fonte:** Adaptado de:\n",
    "\n",
    "> Carnein, M. and Trautmann, H., 2019. Optimizing data stream representation: An extensive survey on stream clustering algorithms. Business & Information Systems Engineering, 61(3), pp.277-297.\n",
    "\n",
    "- *Landmarks* s√£o a escolha mais comum em estrat√©gias batch-incremental. √â preciso definir o tamanho da janela de forma adequada.\n",
    "    - O modelo pode ficar defasado se a janela for muito grande \n",
    "    - Ou o modelo pode n√£o capturar os padr√µes se a janela for muito pequena\n",
    "    - Concept-drift √© um problema e tanto\n",
    "    \n",
    "**Aten√ß√£o**: batch-incremental != mini-batch.\n",
    "Redes neurais podem ser treinadas de forma incremental ou progressiva. No entanto, quest√µes como \"esquecimento catastr√≥fico\" s√£o problem√°ticas. Esse e outros tipos de desafios s√£o tratados na √°rea de pesquisa chamada **continual learning**.\n",
    "\n",
    "## 1.2 Importante lembrar\n",
    "\n",
    "Data streams n√£o s√£o, necessariamente, s√©ries temporais! ü§Ø\n",
    "\n",
    "Mas qual √© a diferen√ßa, ent√£o?\n",
    "\n",
    "Basicamente, em streams n√£o necessariamente temos depend√™ncias temporais expl√≠citas como em s√©ries temporais. Por exemplo: rede de sensores.\n",
    "\n",
    "Os dados chegam temporalmente organizados, mas cada sensor tem uma taxa de transmiss√£o espec√≠fica, ou um delay espec√≠fico. Alguns sensores pode falhar... outros serem adicionados. E assim por diante.\n",
    "\n",
    "A ordem de chegada n√£o importa... tanto, mas importa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Batch vs. Online\n",
    "\n",
    "Uma boa introdu√ß√£o acerca da \"migra√ß√£o\" de batch para online est√° dispon√≠vel no [site](https://riverml.xyz/latest/examples/batch-to-online/) do River. Aqui eu s√≥ quero dar uma vis√£o bem geral das diferen√ßas. Entraremos em mais detalhes posteriormente nas min√∫cias de avalia√ß√£o de modelos em Online Learning.\n",
    "\n",
    "\n",
    "Uma poss√≠vel valida√ß√£o de um modelo tradicional de aprendizado de m√°quina poderia ter essa \"cara\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = load_wine()\n",
    "\n",
    "X, y = data.data, data.target\n",
    "kf = KFold(shuffle=True, random_state=8, n_splits=10)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_tr, X_ts = X[train], X[test]\n",
    "    y_tr, y_ts = y[train], y[test]\n",
    "    \n",
    "    dt  = DecisionTreeClassifier(max_depth=5, random_state=93)\n",
    "    dt.fit(X_tr, y_tr)\n",
    "    \n",
    "    accs.append(accuracy_score(y_ts, dt.predict(X_ts)))\n",
    "\n",
    "print(f\"Acur√°cia m√©dia: {sum(accs) / len(accs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparem que todo o conjunto de dados est√° dispon√≠vel e carregado em mem√≥ria. O algoritmo de √°rvore de decis√£o pode percorrer os dados de treino quantas vezes forem necess√°rias. Os dados de teste (valida√ß√£o, no nosso caso) nunca s√£o utilizados para treino.\n",
    "\n",
    "No fim das contas, usar√≠amos o conjunto completo para treinar um modelo final (supondo que j√° encontramos um conjunto adequado de hiper-par√¢metros). Uma vez treinado, esse modelo seria utilizado para fazer predi√ß√µes para novas amostras (de vinhos, nesse caso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics\n",
    "from river import stream\n",
    "from river import tree\n",
    "\n",
    "\n",
    "acc = metrics.Accuracy()\n",
    "ht = tree.HoeffdingTreeClassifier(max_depth=5, grace_period=20)\n",
    "\n",
    "for x, y in stream.iter_sklearn_dataset(load_wine()):\n",
    "    # M√©trica atualizada antes do treinamento\n",
    "    acc.update(y, ht.predict_one(x))\n",
    "    # Modelo treinado amostra-a-amostra\n",
    "    ht.learn_one(x, y)\n",
    "\n",
    "print(f\"Acur√°cia: {acc.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, estamos percorrendo cada exemplo do conjunto de dados de forma sequencial. Os exemplos poderiam ser carregados diretamente do disco, de algum webservice, ou de onde sua imagina√ß√£o te levar, sem a necessidade de salvar em mem√≥ria nada.\n",
    "\n",
    "Cada amostra √© primeiramente utilizada para teste e depois passada para o modelo. Tudo √© atualizado uma amostra por vez. Notem que n√£o podemos comparar diretamente os desempenhos obtidos porque a estrat√©gia de avalia√ß√£o foi diferente nos dois casos.\n",
    "\n",
    "Poder√≠amos ainda (pseudo) embaralhar os dados antes de passar para o modelo, se temos plena confian√ßa que os dados s√£o estacion√°rios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estruturas necess√°rias: exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from river import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado esse choque inicial, vamos prosseguir com calma e primeiramente pensar em alguns aspectos importantes antes de vermos os algoritmos de aprendizado de m√°quina online.\n",
    "\n",
    "## 3.1. Um exemplo, para aquecimento cerebral\n",
    "\n",
    "Vamos supor que queremos calcular estat√≠sticas para dados que chegam a todo momento:\n",
    "\n",
    "- M√©dia\n",
    "- Vari√¢ncia\n",
    "- ...\n",
    "\n",
    "Hora de simular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "valores = []\n",
    "stds_batch = []\n",
    "\n",
    "for _ in range(50000):\n",
    "    v = rng.gauss(5, 3)\n",
    "    valores.append(v)\n",
    "    \n",
    "    stds_batch.append(np.std(valores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padr√£o o numpy calcula o desvio padr√£o populacional! Para usar a vers√£o amostral precisamos passar `ddof=1` como par√¢metro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "stds_incr = []\n",
    "var = stats.Var(ddof=0)\n",
    "\n",
    "for _ in range(50000):\n",
    "    v = rng.gauss(5, 3)\n",
    "    var.update(v)\n",
    "    stds_incr.append(var.get() ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√° que d√° alguma diferen√ßa? E ser√° que funciona?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_erros = 0\n",
    "\n",
    "for batch, incr in zip(stds_batch, stds_incr):\n",
    "    s_erros += (batch - incr)\n",
    "\n",
    "s_erros, s_erros / len(stds_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... parece convincente. Mas e se o cen√°rio fosse diferente? Se ao inv√©s de calcularmos o desvio padr√£o e irmos aumentando a quantidade de dados, quisessemos descobrir um percentil das √∫ltimas `N` amostras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)\n",
    "\n",
    "tam = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "buffer = []\n",
    "percs75_batch = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    v = rng.uniform(-100, 100)\n",
    "    buffer.append(v)\n",
    "    if len(buffer) <= tam:\n",
    "        continue\n",
    "        \n",
    "    percs75_batch.append(np.quantile(buffer, q=0.75))\n",
    "    buffer.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos fazer um pouco melhor que isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qtl = stats.RollingQuantile(window_size=tam, q=0.75)\n",
    "percs75_incr = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    v = rng.uniform(-100, 100)\n",
    "    qtl.update(v)\n",
    "    if len(qtl) <= tam:\n",
    "        continue\n",
    "        \n",
    "    percs75_incr.append(qtl.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_erros = 0\n",
    "\n",
    "for batch, incr in zip(percs75_batch, percs75_incr):\n",
    "    s_erros += (batch - incr)\n",
    "\n",
    "s_erros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero t√™-los convencido! O [m√≥dulo](https://riverml.xyz/dev/api/overview/#stats) `stats` do River tem v√°rias fun√ß√µes √∫teis para sumariza√ß√£o de dados de forma incremental. Vale a pena checar! üßê\n",
    "\n",
    "A raz√£o pela qual eu quis mostrar tudo isso √© porque v√°rios desses algoritmos s√£o os \"tijolos\" que comp√µem os algoritmos de aprendizado de m√°quina. Uma receita breve para online learning:\n",
    "\n",
    "- A jun√ß√£o de m√©tricas estat√≠sticas incrementais\n",
    "- Algumas grandezas probabil√≠sticas\n",
    "- Algumas teorias de aprendizado de m√°quina que s√£o gen√©ricas e n√£o limitadas ao cen√°rio in-batch\n",
    "- Gradiente descendente\n",
    "- *otras cositas*\n",
    "\n",
    "Com isso tudo √© poss√≠vel formar boa parte dos algoritmos de aprendizado incremental. Mas isso √© extremamente gen√©rico de se dizer, n√£o √©? Bom, no fim das contas, o aprendizado de m√°quina tradicional tamb√©m \"se resume\" a algumas coisas pontuais, mas que s√£o extremamente abrangentes por si s√≥.\n",
    "\n",
    "Que tal entendermos um pouco de como os exemplos anteriores funcionam e por que eles funcionam?\n",
    "\n",
    "## 3.2. Uma (extremamente) breve reflex√£o sobre complexidade dos algoritmos\n",
    "\n",
    "Quanto custa para calcular a vari√¢ncia (no caso, desvio padr√£o) e o percentil nos exemplos anteriores?\n",
    "\n",
    "**Modo batch**\n",
    "\n",
    "Vari√¢ncia:  $\\dfrac{\\sum_i^N (x_i - \\bar{x})}{N - 1}$\n",
    "\n",
    "- M√©dia √© calculada com o custo $O(n)$ -> todos os elementos devem ser somados e divididos pelo total de observa√ß√µes\n",
    "- Com a m√©dia em m√£os, precisamos calcular o desvio de cada elemento para a m√©dia e somar tais desvios: $O(n)$\n",
    "- No fim das contas, o custo final √© $O(n)$ (na nota√ß√£o assint√≥tica), mas tivemos que percorrer todos os dados duas vezes (e, consequentemente, armazen√°-los).\n",
    "- Esse algoritmo tamb√©m apresenta problemas de estabilidade, quando o n√∫mero de observa√ß√µes √© muito grande. Pode gerar erros num√©ricos de aproxima√ß√£o.\n",
    "\n",
    "Percentil:\n",
    "\n",
    "- Pegue um exemplo novo e remova o mais antigo\n",
    "- Ordene os dados: algo em torno de $O(n\\log n)$ (n √© o tamanho do buffer)\n",
    "- Encontre a posi√ß√£o correta, interpole e retorne\n",
    "\n",
    "Se esse processo √© repetido v√°rias e v√°rias vezes...\n",
    "\n",
    "**Modo incremental**\n",
    "\n",
    "\n",
    "Vari√¢ncia (algoritmo de Welford):\n",
    "\n",
    "- Precisamos de algumas vari√°veis:\n",
    "    - $n$: n√∫mero de observa√ß√µes\n",
    "    - $\\overline{x}_n$: a m√©dia da amostral, ap√≥s $n$ observa√ß√µes\n",
    "    - $M_{2, n}$: estat√≠stica de segunda ordem que gerar√° a vari√¢ncia\n",
    "- As atualiza√ß√µes das estat√≠sticas se d√£o na seguinte forma:\n",
    "    - $\\overline{x}_n = \\overline{x}_{n-1} + \\dfrac{x_n - \\overline{x}_{n-1}}{n}$\n",
    "    - $M_{2,n} = M_{2,n-1} + (x_n - \\overline{x}_{n-1})(x_n - \\overline{x}_n)$\n",
    "- E as estat√≠sticas s√£o inicializadas da seguinte forma:\n",
    "    - $\\overline{x}_{0} \\leftarrow 0$\n",
    "    - $M_{2,0} \\leftarrow 0$\n",
    "- Para obter a vari√¢ncia amostral basta usar: $s_n^2 = \\dfrac{M_{2,n}}{n-1}$, para todo $n > 1$\n",
    "- De brinde, obtemos um preditor robusto para a m√©dia ü§ì\n",
    "\n",
    "\n",
    "Percentil:\n",
    "\n",
    "- Mantemos dois buffers\n",
    "   - Um com os dados na ordem em que chegam\n",
    "   - Outro com os dados ordenados: o custo de inser√ß√£o de um novo ponto em um vetor j√° ordenado √© $O(\\log n)$\n",
    "   - A remo√ß√£o de um valor no buffer ordenado √© $O(n)$. No buffer n√£o-ordenado √© $O(1)$\n",
    "   - O c√°lculo do percentil usa o buffer ordenado\n",
    "   \n",
    "No fim das contas, sempre buscamos que cada atualiza√ß√£o em uma m√©trica ou modelo de aprendizado tenha um custo constante ($O(1)$). Se isso n√£o for poss√≠vel, ent√£o um custo sub-linear √© o objetivo!\n",
    "\n",
    "---\n",
    "\n",
    "Antes de prosseguirmos, vou mostrar mais uma aplica√ß√£o legal de m√©tricas incrementais, com requintes de processamento distribuido.\n",
    "\n",
    "**Situa√ß√£o hipot√©tica:**\n",
    "\n",
    "E se estiv√©ssemos calculando estat√≠sticas de alguma coisa, mas a coleta era feita de forma separada? Por exemplo, estamos calculando a vari√¢ncia de alguma coisa a n√≠vel estadual, mas a coleta √© feita por munic√≠pio?\n",
    "\n",
    "(Eu sou paranaense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_ca = [rng.gauss(1500, 200) for _ in range(15000)]\n",
    "dados_lndrn = [rng.gauss(2500, 500) for _ in range(600000)]\n",
    "\n",
    "np.var(dados_ca), np.var(dados_lndrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se quisermos calcular a vari√¢ncia (ou m√©dia) total de todos os munic√≠pios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_parana = []\n",
    "\n",
    "# dados_parana.extend(dados_abati√°)\n",
    "# ...\n",
    "dados_parana.extend(dados_ca)\n",
    "# ...\n",
    "dados_parana.extend(dados_lndrn)\n",
    "# ...\n",
    "# dados_parana.extend(dados_xambr√™)\n",
    "\n",
    "len(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(dados_parana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√≥s j√° sabemos como fazer esse mesmo processo de forma incremental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estou considerando que todos os dados foram coletados, mas poderia usar o padr√£o, ddof=1\n",
    "var_ca = stats.Var(ddof=0)\n",
    "var_lndrn = stats.Var(ddof=0)\n",
    "\n",
    "for p in dados_ca:\n",
    "    var_ca.update(p)\n",
    "    \n",
    "for p in dados_lndrn:\n",
    "    var_lndrn.update(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ca.get(), var_lndrn.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posso usar `stats.Mean` para obter a m√©dia. Mas se lembrarmos bem, o algoritmo de Welford tem um preditor de m√©dia \"l√° no meio\", n√£o tem?\n",
    "\n",
    "Voil√†!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ca.mean.get(), np.mean(dados_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vem a parte mais legal üôÉ\n",
    "\n",
    "Como obtemos as estat√≠sticas para o estado inteiro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine que temos um for somando as estat√≠sticas de todos os estados\n",
    "\n",
    "var_parana = var_ca + var_lndrn  # + os outros municipios\n",
    "\n",
    "var_parana.get(), np.var(dados_parana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_parana.mean.get(), np.mean(dados_parana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se a bela e formosa cidade de C√¢ndido de Abreu tivesse sido esquecida? Os dados tivessem sido perdidos, sei l√°...\n",
    "\n",
    "(quando eu era crian√ßa, minha cidade nem aparecia nos mapas impressos do Paran√°, vai saber...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ca_backup = var_parana - var_lndrn  # - os outros municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_ca.get(), var_ca_backup.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ca.mean.get(), var_ca_backup.mean.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No fim das contas, sempre existe um trade-off entre mem√≥ria e tempo de processamento (e a quantidade de \"passadas\" nos dados) e a precis√£o dos resultados obtidos. Muitos dos algor√≠tmos de online learning incluem um par√¢metro ($\\delta$) que indica a porcentagem de \"certeza\" que voc√™ deseja ter nos seus resultados. Em geral, quanto mais certeza, mais tempo leva para tomar as decis√µes.\n",
    "\n",
    "\n",
    "# 4. Por que usar dicion√°rios (ou, por que usar uma representa√ß√£o esparsa)?\n",
    "\n",
    "Um as primeiras coisas que podem chamar a aten√ß√£o no River √© o tipo de dados que √© utilizado: dicion√°rios python.\n",
    "\n",
    "- Chave x valor: chaves s√£o √∫nicas\n",
    "- Valores acessados via chave, ao inv√©s de √≠ndice\n",
    "- Dicion√°rios s√£o estruturas naturalmente esparsas\n",
    "- Diferentemente de arrays, vetores, matrizes (e etc.) n√£o possuem uma ordena√ß√£o expl√≠cita\n",
    "- Podem ser extendidos\n",
    "- Podem ter vari√°veis de tipo misto\n",
    "\n",
    "Exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "x = {\n",
    "    \"batata\": 3,\n",
    "    \"carro\": 2,\n",
    "    \"data\": datetime.now(),\n",
    "    \"sim_ou_n√£o\": \"sim\"\n",
    "}\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"mais um\"] = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x[\"data\"]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse tipo de estrutura √© muito parecida com o popular formato JSON (para transfer√™ncia de dados)!\n",
    "\n",
    "Que tal compararmos com o que √© mais usual?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X[0, :], data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0], data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos colocar o sklearn √† prova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = X[:-2, :], y[:-2]\n",
    "X_ts, y_ts = X[-2:, :], y[-2:]\n",
    "\n",
    "X_tr.shape, X_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_tr, y_tr)\n",
    "\n",
    "nb.predict(X_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, e se uma feature estivesse faltando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nb.predict(X_ts[:, 1:])\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em Online Learning n√≥s n√£o dever√≠amos ficar nos preocupando com \"coisa pouca\" assim. Brincadeiras a parte, em um cen√°rio de aprendizado online, sensores podem falhar, novos dados podem surgir, entre muitas outras coisas que podem alterar os dados de entrada. Precisamos de uma representa√ß√£o e modelos robustos quanto a isso!\n",
    "\n",
    "Com o River, a vasta maioria dos modelos est√° pronta para lidar com esse tipo de problema! üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import naive_bayes\n",
    "\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "dataset = stream.iter_sklearn_dataset(load_wine())\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "# Chance de feature ser ignorada\n",
    "del_chance = 0.2\n",
    "\n",
    "n_linhas_incompletas = 0\n",
    "for i, (x, y) in enumerate(dataset):\n",
    "    if i == 176:\n",
    "        break\n",
    "    \n",
    "    x_copy = x.copy()\n",
    "    aux = 0\n",
    "    for xi in x:\n",
    "        if rng.random() <= del_chance:\n",
    "            del x_copy[xi]\n",
    "            aux = 1\n",
    "        \n",
    "        # Atualiza o n√∫mero de linhas incompletas\n",
    "        n_linhas_incompletas += aux\n",
    "    \n",
    "    gnb.learn_one(x_copy, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.predict_proba_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos bagun√ßar a √∫ltima amostra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = next(dataset)\n",
    "list(x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou tirar um c√≥pia do `x` e remover umas coisas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy = x.copy()\n",
    "\n",
    "del x_copy[\"malic_acid\"]\n",
    "del x_copy[\"hue\"]\n",
    "del x_copy[\"flavanoids\"]\n",
    "\n",
    "x_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√° que o nosso modelo d√° conta do recado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.predict_proba_one(x_copy), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se ao inv√©s de diminuir o n√∫mero de features aumentasse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"primeira extra\"] = 7.89\n",
    "x[\"segunda extra\"] = 2\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.learn_one(x, y)\n",
    "\n",
    "gnb.predict_one({\"primeira extra\": 7.8, \"segunda extra\": 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada tipo de modelo implementa estrat√©gias diferentes para lidar com atributos emergentes ou faltantes!\n",
    "\n",
    "No nosso exemplo, \"1\" era a classe majorit√°ria. Essa foi a escolha feita pelo GaussianNB, j√° que h√° pouca informa√ß√£o acerca dos dois atributos extra que adicionamos. Mas eles j√° fazem parte do modelo e ser√£o atualizados caso novas observa√ß√µes cheguem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Como avaliar um modelo?\n",
    "\n",
    "J√° vimos em exemplos passados que os dados foram primeiramente utilizados para teste e depois para treino. Nada de Cross-validation, Leave-one-out, holdout e coisas do tipo.\n",
    "\n",
    "Esse tipo de avalia√ß√£o se aproxima mais de um cen√°rio de produ√ß√£o real. Normalmente, obtemos um dado sem a sua label (no caso supervisionado, obviamente) e precisamos fazer predi√ß√µes. S√≥ depois de um tempo a verdadeira label daquele exemplo ser√° conhecida.\n",
    "\n",
    "Nos exemplos at√© aqui, n√≥s assumimos que logo ap√≥s o treinamento do modelo com uma amostra, a label √© revelada. No entanto, um cen√°rio ainda mais real√≠stico √© aquele onde existe um *delay* entre a predi√ß√£o e a chegada da label. Em alguns casos, certos exemplos podem nunca ter sua label obtida!\n",
    "\n",
    "Esse tipo de estrat√©gia de avalia√ß√£o √© chamada de \"valida√ß√£o progressiva\" (*progressive validation*) ou \"*prequential*\".\n",
    "\n",
    "Deixo esse [√≥timo post do Max Halford](https://maxhalford.github.io/blog/online-learning-evaluation/), onde esse tema √© discutido em detalhes.\n",
    "\n",
    "No River, podemos utilizar a fun√ß√£o `progressive_val_score` dispon√≠vel no m√≥dulo `evaluate` para realizar valida√ß√µes progressivas! Daqui para frente, essa fun√ß√£o ser√° utilizada.\n",
    "\n",
    "Obviamente, podemos tamb√©m escrever alguns `for` e customizar a estrat√©gia de avalia√ß√£o. Fica de acordo com o crit√©rio e a necessidade de cada um!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river import evaluate\n",
    "from river import metrics\n",
    "from river import synth\n",
    "\n",
    "\n",
    "def label_delay(x, y):\n",
    "    return rng.randint(0, 100)\n",
    "\n",
    "\n",
    "rng = random.Random(8)\n",
    "dataset = synth.RandomRBF(seed_sample=7, seed_model=9)\n",
    "model = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "# Podemos combinar m√©tricas com operadores de pipeline!\n",
    "metric = metrics.Accuracy() + metrics.MicroF1() + metrics.BalancedAccuracy()\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=dataset.take(50000),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    print_every=5000,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    delay=label_delay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Concept drift\n",
    "\n",
    "Um dos aspectos centrais em online learning reside no fato que esperamos que as distribui√ß√µes dos dados podem ser n√£o-estacion√°rias. Mas o que isso significa?\n",
    "\n",
    "Primeiro, vamos pensar num exemplo de distribu√ß√£o estacion√°ria:\n",
    "\n",
    "> Sabe quando ouvimos falar que a GRANDE-EMPRESA-HYPADA lan√ßou uma rede neural MASTER-BLASTER-ULTRA-POWER-3, com 3 tro√ßalh√µes de par√¢metros, treinada por 3 meses com a energia suficiente para alimentar cidades? E sabe quando ouvimos falar que a base de dados utilizada foi gigante?\n",
    "\n",
    "Pois bem, os dados n√£o mudam. As regras lingu√≠sticas no textos de entrada (supondo um modelo de linguagem natural) ou a sem√¢ntica visual das imagens (supondo um modelo de vis√£o computacional), ou qualquer outro exemplo, tudo isso √© est√°tico. Um cachorro continuar√° sendo um cachorro (independente do √¢ngulo -- dependendo da forma de capta√ß√£o das imagens isso poderia ser um problema). Uma palavra tem um conjunto de sin√¥nimos e significados.\n",
    "\n",
    "A regra do jogo n√£o-muda. Mas e se mudasse?\n",
    "\n",
    "Essa mudan√ßa, ou deriva de conceito (concept drift) pode ocorrer em problemas do mundo real. Exemplo:\n",
    "\n",
    "- padr√µes de consumo (papel higi√™nico e alcool em gel no in√≠cio da pandemia)\n",
    "- quest√µes relacionadas a clima: energia sustent√°vel\n",
    "- tr√¢nsito, rotas\n",
    "\n",
    "Umas das √°reas de pesquisa (sim, uma √°rea completa de pesquisa) em online learning busca criar detectores para essas situa√ß√µes, bem como algoritmos de aprendizado de m√°quina que sejam capazes de se adaptar mudan√ßas de conceitos.\n",
    "\n",
    "Estou longe de ser um especialista nesse t√≥pico, mas vou dar um panorama de como as coisas acontecem.\n",
    "\n",
    "Suponha que temos um problema de classifica√ß√£o e estamos monitorando os erros do nosso classificador. N√≥s assinalamos com $0$ quando o modelo acerta (erro zero) e $1$ quando o modelo erra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = random.Random(8)\n",
    "\n",
    "for _ in range(10):\n",
    "    print(rng.choices([0, 1], weights=[0.7, 0.3])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos passar esses valores para um detector de drifts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import drift\n",
    "\n",
    "detector = drift.ADWIN(delta=0.01)\n",
    "\n",
    "vals = rng.choices([0, 1], weights=[0.7, 0.3], k=500)\n",
    "for i, v in enumerate(vals):\n",
    "    in_drift, _ = detector.update(v)\n",
    "    \n",
    "    if in_drift:\n",
    "        print(f\"Drift detectado em {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se a distribui√ß√£o mudar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = drift.ADWIN(delta=0.05)\n",
    "\n",
    "vals = rng.choices([0, 1], weights=[0.7, 0.3], k=500)\n",
    "vals.extend(rng.choices([0, 1], weights=[0.2, 0.8], k=500))\n",
    "for i, v in enumerate(vals):\n",
    "    in_drift, _ = detector.update(v)\n",
    "    \n",
    "    if in_drift:\n",
    "        print(f\"Drift detectado em {i}\")\n",
    "        # Pratica usual\n",
    "        detector.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ADWIN √© um dos detectores mais utilizados, mas existem v√°rias alternativas. Al√©m disso, normalmente, os detectores s√£o utilizados como componentes na cria√ß√£o de modelos preditivos. A forma na qual eles s√£o utilizados difere de modelo para modelo. Uma caracter√≠stica √© comum entre a maioria dos detectores de drift: eles s√£o univariados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Exemplos de algoritmos\n",
    "\n",
    "Existem muitos algoritmos de aprendizado online. Uns s√£o bem diferentes, outros s√£o modifica√ß√µes de outros algoritmos. Assim como em aprendizado de m√°quina tradicional, existem op√ß√µes para todo gosto.\n",
    "\n",
    "As listas a seguir n√£o s√£o extensivas de modo algum. S√£o apenas o que eu fui lembrando, tenho certa familiaridade, e o que eu vejo de popular por a√≠ (obviamente com o meu vi√©s pessoal). Uma boa pedida √© consultar a documenta√ß√£o do River para ver o que h√° de dispon√≠vel por l√°!\n",
    "\n",
    "Mostrarei de forma breve seu uso e, quando aplic√°vel, quais dos seus hiper-par√¢metros s√£o os mais \"sens√≠veis\", na minha experi√™ncia.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "**Dica:** Se **d√∫vidas** espec√≠ficas surgirem acerca de alguma fam√≠lia, me **interrompam**. Posso **comentar** mais **detalhes** e ir deixando a conversa mais t√©cnica.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Classifica√ß√£o\n",
    "\n",
    "Abordaremos uma lista de algoritmos para classifica√ß√£o. Se um algoritmo foi projetado apenas para classifica√ß√£o bin√°ria e o problema em quest√£o √© multiclasses, as ferramentas do m√≥dulo `multiclass` podem ser utilizadas como um wrapper:\n",
    "\n",
    "- `OneVsOneClassifier`\n",
    "- `OneVsRestClassifier`\n",
    "- `OutputCodeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1. Logistic Regression\n",
    "\n",
    "Vers√£o incremental de Logistic Regression (para classifica√ß√£o bin√°ria). Pode ser treinada com v√°rios otimizadores. Por padr√£o usa o `Stochastic Gradient Descent`.\n",
    "\n",
    "\n",
    "N√£o tenho muitas dicas espec√≠ficas acerca dessa fam√≠lia. Mas todo o conhecimento ligado a redes neurais tende a ser √∫til aqui.\n",
    "\n",
    "√â poss√≠vel ajustar:\n",
    "\n",
    "- O otimizador\n",
    "- O algortmo de inicializa√ß√£o\n",
    "- Adicionar regulariza√ß√£o L2\n",
    "- A fun√ß√£o de perda\n",
    "- entre outros\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from river import linear_model\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "\n",
    "dataset = datasets.Phishing()\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LogisticRegression(optimizer=optim.Adam(), l2=0.01)\n",
    ")\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos inspecionar como as decis√µes foram feitas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma variante de Logistic Regression √© SoftMax Regression (voltada para problemas multi-classe e mais robusta a outliers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageSegments()\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.SoftmaxRegression()\n",
    ")\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric, print_every=200, show_memory=True, show_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2. Hoeffding Tree (e variantes)\n",
    "\n",
    "Est√£o entre os modelos mais populares em stream mining. Historicamente um dos algoritmos mais usados, sen√£o o mais usado. Minha pesquisa de doutorado contempla √°rvores de decis√£o e ensembles online. Existem v√°rios classificadores no River baseados em √°rvores de decis√£o. Grande parte deles pertencem a fam√≠lia das *Hoeffding Trees*.\n",
    "\n",
    "Hoeffding Trees (HT) t√™m esse nome porque elas se baseiam numa grandeza estat√≠stica chamada *Hoeffding bound* para decidir quando fazer uma divis√£o. Essa medida traz ind√≠cios que um split feito de forma incremental seria o mesmo que seria feito em um algoritmo de √°rvore tradicional (desde que observa√ß√µes suficientes sejam feitas).\n",
    "\n",
    "Existem tr√™s variantes principais das HTs:\n",
    "\n",
    "- Hoeffding Tree: vers√£o padr√£o\n",
    "- Hoeffding Adaptive Tree: adiciona detectores de deriva de conceito em cada n√≥ de decis√£o. Se uma mudan√ßa √© detectada, uma nova sub-√°rvore √© treinada (no *background*) e eventualmente vir√° a substituir o ramo afetado.\n",
    "- Extremely Fast Decision Tree: Faz splits mais rapidamente, mas periodicamente revisita as decis√µes feitas e vai reconstruindo as √°rvores.\n",
    "\n",
    "**Principais par√¢metros para ajuste comum a todas as HTs:**\n",
    "\n",
    "- `grace_period`: intervalos entre tentativas de *splits*.\n",
    "- `split_confidence`: o qu√£o \"certas\" sobre uma decis√£o as √°rvores devem estar, de forma fazer um *split*. A \"certeza\" √© dada por `1 - split_confidence`.\n",
    "- `tie_threshold`: threshold abaixo do qual um split ser√° feito, mesmo se n√£o houver plena certeza que o melhor candidato para *split* √© realmente a melhor escolha.\n",
    "- `max_depth`: profundeza m√°xima que uma √°rvore pode alcan√ßar.\n",
    "\n",
    "Eu escrevi um [tutorial](https://riverml.xyz/dev/user-guide/on-hoeffding-trees/) sobre HTs que aprofunda mais o que √© poss√≠vel se fazer com esse tipo de preditor.\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river import tree\n",
    "\n",
    "\n",
    "dataset = synth.RandomRBFDrift(\n",
    "    seed_model=7, seed_sample=8, change_speed=0.0001, n_classes=3,\n",
    ").take(15000)\n",
    "model = tree.HoeffdingAdaptiveTreeClassifier(seed=42)\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric, print_every=1000, show_memory=True, show_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como j√° vimos anteriormente, podemos visualizar a estrutura da √°rvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamb√©m √© poss√≠vel inspecionar como uma decis√£o √© tomada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = synth.RandomRBFDrift(\n",
    "    seed_model=7, seed_sample=8, change_speed=0.0001, n_classes=3,\n",
    ").take(15000)\n",
    "\n",
    "x, y = next(dataset)\n",
    "\n",
    "print(model.debug_one(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3. Naive Bayes\n",
    "\n",
    "O Naive Bayes √© inerentemente incremental. Assim, √© poss√≠vel atualizar as contagens ou estimativas das distribui√ß√µes de forma incremental.\n",
    "\n",
    "Modelos dispon√≠veis:\n",
    "\n",
    "- BernoulliNB, ComplementNB e MultinomialNB: voltados para os casos onde os dados s√£o contagens (bag-of-words), ou a sa√≠da do TF-IDF.\n",
    "-  GaussianNB: discretiza as features num√©ricas utilizando uma distribui√ß√£o gaussiana por classe.\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = synth.RandomRBFDrift(\n",
    "    seed_model=7, seed_sample=8, change_speed=0.0001, n_classes=3,\n",
    ").take(15000)\n",
    "\n",
    "\n",
    "# Note que o modelo selecionado n√£o tem trata a deriva de conceitos\n",
    "model = naive_bayes.GaussianNB()\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric, print_every=1000, show_memory=True, show_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4. Adaptive Random Forest\n",
    "\n",
    "A adaptive random forest (ARF) √© uma vers√£o incremental do algoritmo Random Forest e combinas os seguintes ingredientes:\n",
    "\n",
    "- Hoeffding Trees com pitadas de aleatoriadade, como *base learners* (ingrediente principal)\n",
    "- Detectores de deriva de conceito por √°rvore\n",
    "    - √°rvores \"reserva\" s√£o treinadas em *background* caso drifts s√£o detectados\n",
    "- Bagging na vers√£o online\n",
    "\n",
    "Al√©m de todos os par√¢metros das HTs, alguns par√¢metros not√°veis da ARF s√£o:\n",
    "\n",
    "- `warning_detector` e `drift_detector`: detectores de warning e drift\n",
    "- `n_models`: o n√∫mero de √°rvores\n",
    "- `max_features`: o n√∫mero de features que ser√° considerado por √°rvore durante *splits*\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import ensemble\n",
    "\n",
    "\n",
    "dataset = synth.RandomRBFDrift(\n",
    "    seed_model=7, seed_sample=8, change_speed=0.0001, n_classes=3,\n",
    ").take(15000)\n",
    "\n",
    "model = ensemble.AdaptiveRandomForestClassifier(seed=8)\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric, print_every=1000, show_memory=True, show_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5. Streaming Random Patches\n",
    "\n",
    "Na ARF e random forest em geral, cada vez que um n√≥ da √°rvore √© dividido, um novo sub-conjunto das features √© selecionado. Apenas esse subconjunto √© considerado nas decis√µes. Esse processo pode ser referido como amostragem local de features. A (A)RF tamb√©m faz amostragem de inst√¢ncias com reposi√ß√£o (*bagging*).\n",
    "\n",
    "O Streaming Random Patches (SRP) tamb√©m faz amostragem de inst√¢ncias via bagging. No entanto, a amostragem de features √© global: feita apenas uma vez por modelo no ensemble. Al√©m disso, o SRP n√£o limita os membros do ensemble √† √°rvores de decis√£o: qualquer classificador pode ser utilizado üòÅ\n",
    "\n",
    "A detec√ß√£o e rea√ß√£o a derivas de conceito (concept drift) √© igual ao mecanismo adotado na ARF.\n",
    "\n",
    "Quanto aos hiperpar√¢metros mais not√°veis:\n",
    "\n",
    "- `model`: o classificador base\n",
    "- `n_models`: o n√∫mero de classificadores no ensemble\n",
    "- `warning_detector` e `drift_detector`: o mesmo que na ARF\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import neighbors\n",
    "\n",
    "dataset = synth.RandomRBFDrift(\n",
    "    seed_model=7, seed_sample=8, change_speed=0.0001, n_classes=3,\n",
    ").take(15000)\n",
    "\n",
    "\n",
    "model = ensemble.SRPClassifier(\n",
    "    neighbors.KNNClassifier(),\n",
    "    n_models=5, seed=8,\n",
    "    training_method=\"subspaces\"\n",
    ")\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric, print_every=1000, show_memory=True, show_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Regress√£o\n",
    "\n",
    "\n",
    "Para regress√£o, vou adotar o mesmo dataset em todos os casos, para termos uma ideia das capacidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friedman():\n",
    "    return synth.Friedman(seed=101).take(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. Linear Regression\n",
    "\n",
    "\n",
    "A regress√£o linear permite a explora√ß√£o de v√°rios par√¢metros:\n",
    "\n",
    "- otimizadores\n",
    "- fun√ß√µes de perda\n",
    "- regulariza√ß√£o\n",
    "- estrat√©gias para atualiza√ß√£o do fator de aprendizado\n",
    "- entre outras coisas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | linear_model.LinearRegression()\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | linear_model.LinearRegression(\n",
    "    intercept_lr=0.02, intercept_init=3.5, l2=0.02\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2. Hoeffding Tree\n",
    "\n",
    "(minha pesquisa se situa aqui)\n",
    "\n",
    "Temos tamb√©m vers√µes da HT para regress√£o. Os principais modelos para regress√£o de √∫nico alvo s√£o:\n",
    "\n",
    "- `HoeffdingTreeRegressor`: vers√£o padr√£o do regressor.\n",
    "- `HoeffdingAdaptiveTreeRegressor`: extende o anterior de forma similar √† vers√£o de classifica√ß√£o.\n",
    "\n",
    "Al√©m dos par√¢metros j√° apresentados na √°rvore de classifica√ß√£o, outros par√¢metros importantes s√£o:\n",
    "\n",
    "- `leaf_prediction`: seleciona a estrat√©gia de predi√ß√£o -- regression ou model tree\n",
    "- `leaf_model`: modelo preditivo utilizado nas folhas, no caso das model trees\n",
    "- `splitter`: algoritmo utilizado para lidar com *splits* em atributos num√©ricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | tree.HoeffdingTreeRegressor()\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como usual, podemos inspecionar os modelos baseados em √°rvores de decis√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = next(get_friedman())\n",
    "\n",
    "print(model.debug_one(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"HoeffdingTreeRegressor\"].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou mudar a estrat√©gia de predi√ß√£o, apenas por ilustra√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | tree.HoeffdingTreeRegressor(\n",
    "    leaf_model=linear_model.PARegressor(C=0.1, eps=0.0001)\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querem conhecer um pouco da minha pesquisa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | tree.HoeffdingTreeRegressor(\n",
    "    leaf_prediction=\"adaptive\",\n",
    "    splitter=tree.splitter.QOSplitter(2, allow_multiway_splits=True)  # <- parte da minha pesquisa est√° focada aqui\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minha pesquisa:**\n",
    "\n",
    "> ### *Diminuir os custos computacionais de regressores baseados em √°rvores e regras de decis√£o, bem como ensembles destes preditores.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3. AMRules\n",
    "\n",
    "Adaptive Model Rules.\n",
    "\n",
    "(minha pesquisa se situa aqui tamb√©m)\n",
    "\n",
    "Cria regras de decis√£o baseadas na Hoeffding bound, assim como as √°rvores. √â capaz de fazer dete√ß√£o de anomalias! De fato, o AMRule \"pula\" amostras anomalas durante o treinamento.\n",
    "\n",
    "Tem alguns ajustes muito parecidos com as √°rvores de decis√£o:\n",
    "\n",
    "- `n_min`: equivalente ao `grace_period`\n",
    "- `delta`: equivalente ao  `split_confidence`\n",
    "- `tau`: equivalente `tie_threshold`\n",
    "- `pred_type`: equivalente `leaf_prediction`\n",
    "- `pred_model`: equivalente `leaf_model`\n",
    "- `splitter`\n",
    "\n",
    "Em adi√ß√£o, outros par√¢metros importantes:\n",
    "\n",
    "- `m_min`: n√∫mero de inst√¢ncias que cada regra deve observar antes de come√ßar a detectar anomalias.\n",
    "- `drift_detector`: o detector de concept drift utilizado pelas regras de decis√£o\n",
    "- `anomaly_threshold`: valor de corte para considerar uma amostra an√¥mala. Inst√¢ncias ser√£o consideradas an√¥malas se o `score` delas for menor que esse limiar.\n",
    "- `ordered_rule_set`: define se apenas a primeira regra que d√° \"*match*\" em uma inst√¢ncia ser√° utilizada, ou todas as regras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from river import rules\n",
    "\n",
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | rules.AMRules(\n",
    "    splitter=tree.splitter.TEBSTSplitter(digits=1),  #  <- olha minha pesquisa aqui tamb√©m\n",
    "    drift_detector=drift.ADWIN(),\n",
    "    ordered_rule_set=False,\n",
    "    m_min=100,\n",
    "    delta=0.01\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamb√©m podemos inspecionar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(get_friedman())\n",
    "\n",
    "print(model.debug_one(x))\n",
    "print(f\"Valor esperado: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = model[\"StandardScaler\"].transform_one(x)\n",
    "\n",
    "model[\"AMRules\"].anomaly_score(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(rules.AMRules.anomaly_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4. Adaptive Random Forest\n",
    "\n",
    "(minha pesquisa tamb√©m est√° aqui!)\n",
    "\n",
    "Utiliza uma vers√£o da `HoeffdingTreeRegressor` como preditor base. Tem todos os hiper-par√¢metros da √°rvore de decis√£o e os par√¢metros que j√° foram apresentados na ARF para classifica√ß√£o.\n",
    "\n",
    "Al√©m disso, adiciona um par√¢metro que tende a impactar bastante os resultados:\n",
    "\n",
    "- `agregation_method`: como as predi√ß√µes individuais de cada √°rvore ser√£o combinadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | ensemble.AdaptiveRandomForestRegressor(\n",
    "    seed=7,\n",
    "    aggregation_method=\"median\",\n",
    "    splitter=tree.splitter.QOSplitter(1)\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.5. Streaming Random Patches\n",
    "\n",
    "(minha pesquisa tamb√©m est√° aqui)\n",
    "\n",
    "√â a vers√£o para regress√£o do SRP apresentado anteriormente. Compartilha os mesmos par√¢metros apresentados para o algoritmo de classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | ensemble.SRPRegressor(\n",
    "    model=linear_model.LinearRegression(l2=0.02, intercept_init=3.5, intercept_lr=0.04),\n",
    "    seed=7,\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tamb√©m utilizar Bagging para unir regressores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | ensemble.BaggingRegressor(\n",
    "    model=tree.HoeffdingAdaptiveTreeRegressor(splitter=tree.splitter.QOSplitter(0.5), seed=7),\n",
    "    seed=7,\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Clustering\n",
    "\n",
    "Algoritmos incrementais para clustering devem ser capazes de se adaptarem √†s mudan√ßas constantes nos dados. Por exemplo, alguns clusters podem surgir, outros desaparecerem. √â uma √°rea ativa de pesquisa, com muitos algoritmos dispon√≠veis!\n",
    "\n",
    "Apresentarei um algoritmo particional baseado em prot√≥tipos, para ilustrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. k-Means\n",
    "\n",
    "Existem v√°rias vers√µes incrementais do k-Means. A vers√£o no River adiciona um par√¢metro chamado `halflife` que controla o n√≠vel das atualiza√ß√µes incrementais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import cluster\n",
    "\n",
    "metric = metrics.cluster.Silhouette()\n",
    "model = cluster.KMeans(seed=7)\n",
    "\n",
    "\n",
    "for x, _ in get_friedman():\n",
    "    metric.update(x, model.predict_one(x), model.centers)\n",
    "    model.learn_one(x)\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos diminuir o n√∫mero de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = metrics.cluster.Silhouette()\n",
    "model = cluster.KMeans(n_clusters=3, seed=7)\n",
    "\n",
    "\n",
    "for x, _ in get_friedman():\n",
    "    metric.update(x, model.predict_one(x), model.centers)\n",
    "    model.learn_one(x)\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aumentar o valor de `halflife`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.cluster.Silhouette()\n",
    "model = cluster.KMeans(n_clusters=3, seed=7, halflife=0.7)\n",
    "\n",
    "\n",
    "for x, _ in get_friedman():\n",
    "    metric.update(x, model.predict_one(x), model.centers)\n",
    "    model.learn_one(x)\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Anomaly detection\n",
    "\n",
    "At√© o momento o River conta com um detector de anomalias, que √© a vers√£o incremental da Isolation Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from river import anomaly\n",
    "\n",
    "dataset = datasets.CreditCard()\n",
    "model = preprocessing.MinMaxScaler() | anomaly.HalfSpaceTrees(seed=42, window_size=20)\n",
    "\n",
    "limiar_anomalia = 0.8\n",
    "var = stats.Var()\n",
    "\n",
    "fraudes = []\n",
    "fraudes_preditas_static = []\n",
    "fraudes_preditas_dynamic = []\n",
    "\n",
    "fraudes_match_static = []\n",
    "fraudes_match_dynamic = []\n",
    "\n",
    "metric_static = metrics.BalancedAccuracy() + metrics.Precision() + metrics.Recall() + metrics.F1()\n",
    "metric_dynamic = metrics.BalancedAccuracy() + metrics.Precision() + metrics.Recall() + metrics.F1()\n",
    "\n",
    "for i, (x, y) in enumerate(dataset):\n",
    "    score = model.score_one(x)\n",
    "    model.learn_one(x)\n",
    "    \n",
    "    pred_static = 1 if score > limiar_anomalia else 0\n",
    "    \n",
    "    std = var.get() ** 0.5\n",
    "    pred_dynamic = 1 if score > var.mean.get() + 1.5 * std else 0\n",
    "    \n",
    "    if y == 1:\n",
    "        fraudes.append(i)\n",
    "        \n",
    "        if pred_static == 1:\n",
    "            fraudes_match_static.append(i)\n",
    "        \n",
    "        if pred_dynamic == 1:\n",
    "            fraudes_match_dynamic.append(i)\n",
    "                \n",
    "    \n",
    "    if pred_static == 1:\n",
    "        fraudes_preditas_static.append(i)\n",
    "        \n",
    "    if pred_dynamic == 1:\n",
    "        fraudes_preditas_dynamic.append(i)\n",
    "    \n",
    "    metric_static.update(y, pred_static)\n",
    "    metric_dynamic.update(y, pred_dynamic)\n",
    "    var.update(score)\n",
    "    \n",
    "    if i >= 100000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"N√∫mero de amostras: {i}\")\n",
    "print(f\"N√∫mero de anomalias: {len(fraudes)}\")\n",
    "print(f\"N√∫mero de anomalias detectadas (est√°tico): {len(fraudes_preditas_static)}\")\n",
    "print(f\"N√∫mero de anomalias detectadas (din√¢mico): {len(fraudes_preditas_dynamic)}\")\n",
    "print(f\"Match detec√ß√µes (est√°tico): {len(fraudes_match_static) / len(fraudes)}\")\n",
    "print(f\"Match detec√ß√µes (din√¢mico): {len(fraudes_match_dynamic) / len(fraudes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos checar como estava o limiar din√¢mico no final?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.mean.get() + 1.5 * (var.get() ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura extra!\n",
    "\n",
    "Um membro do [Spike](https://www.spikelab.xyz/) escreveu um tutorial muito bom sobre detec√ß√£o de anomalias usando River: https://medium.com/spikelab/anomalies-detection-using-river-398544d3536\n",
    "\n",
    "\n",
    "Ele aborda um cen√°rio de produ√ß√£o real e vai muito al√©m do meu simples exemplo. Recomendo muito a leitura!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Expert stuff\n",
    "\n",
    "O m√≥dulo `expert` traz utilidades para sele√ß√£o e combina√ß√£o de modelos.\n",
    "\n",
    "Abordarei dois exemplos:\n",
    "\n",
    "1. Sele√ß√£o de modelos\n",
    "2. Combina√ß√£o de modelos\n",
    "\n",
    "\n",
    "## 8.1. Selecionando um modelo de forma online\n",
    "\n",
    "Suponha que eu tenho um conjunto de hiper-par√¢metros que gostaria de avaliar, mas n√£o gostaria de rodar todos os modelos para descobrir qual √© o melhor. Vamos usar a regress√£o linear como exemplo aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LinearRegression(intercept_lr=.01, intercept_init=3.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import utils\n",
    "\n",
    "models = utils.expand_param_grid(model, {\n",
    "    'LinearRegression': {\n",
    "        'optimizer': [\n",
    "            (optim.SGD, {'lr': [.1, .01, .005]}),\n",
    "            (optim.Adam, {'beta_1': [.01, .001], 'lr': [.1, .01, .001]}),\n",
    "            (optim.NesterovMomentum, {'rho': [.8, .9, .95], 'lr': [.001, .02, .04, .1]}),\n",
    "        ],\n",
    "        'l2': [.0, .1, .01, .001],\n",
    "        'loss': [optim.losses.Absolute(), optim.losses.Squared()]\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river import expert\n",
    "\n",
    "\n",
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = expert.SuccessiveHalvingRegressor(\n",
    "    models=models,\n",
    "    budget=5000,\n",
    "    metric=metrics.RMSE()\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.best_model._get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Combina√ß√£o de modelos\n",
    "\n",
    "N√≥s j√° vimos alguns ensembles, mas tamb√©m √© poss√≠vel combinar modelos de outras formas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    tree.HoeffdingTreeRegressor(\n",
    "        splitter=tree.splitter.QOSplitter(),\n",
    "        leaf_prediction=\"adaptive\"\n",
    "    ),\n",
    "    rules.AMRules(\n",
    "        drift_detector=drift.ADWIN(),\n",
    "        splitter=tree.splitter.QOSplitter()\n",
    "    ),\n",
    "    tree.SGTRegressor(\n",
    "        grace_period=50,\n",
    "        feature_quantizer=tree.splitter.DynamicQuantizer(),\n",
    "        init_pred=3.5\n",
    "    ),\n",
    "]\n",
    "\n",
    "metric = metrics.MAE() + metrics.RMSE() + metrics.R2()\n",
    "model = preprocessing.StandardScaler() | expert.EWARegressor(\n",
    "    regressors=regressors,\n",
    "    learning_rate=0.04\n",
    ")\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=get_friedman(),\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Pipelines e pr√©-processamento\n",
    "\n",
    "Voc√™s notaram que eu tenho usado muito os operadores \"|\" e \"+\" em alguns contextos?\n",
    "\n",
    "Esses operadores s√£o utilizados para criar pipelines. Eles s√£o algo que chamamos de \"sugar syntax\".\n",
    "\n",
    "No River n√≥s podemos usar operadores expl√≠citos, assim como no sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose\n",
    "\n",
    "\n",
    "model = compose.Pipeline(preprocessing.StandardScaler(), linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos supor que no exemplo anterior, algumas das features que seriam passadas ao nosso modelo eram categ√≥ricas. Poder√≠amos aplicar um encoding nesses exemplos para garantir que nosso modelo funcionaria com a regress√£o linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "pipeline = compose.Pipeline(\n",
    "    compose.TransformerUnion(\n",
    "        compose.SelectType(numbers.Number),\n",
    "        compose.Pipeline(\n",
    "            compose.SelectType(str),\n",
    "            preprocessing.OneHotEncoder()\n",
    "        ),\n",
    "    ),\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LinearRegression()\n",
    ")\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que coisa linda n√©? Eu \"escondi o ouro\" e propositalmente n√£o mostrei essa visualiza√ß√£o anteriormente. Muito √∫til para *debugging*. Pr√°tico? Pode ficar ainda melhor!\n",
    "\n",
    "Sugar syntax! Vou montar o mesmo pipeline sem usar explicitamente os componentes de `compose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    (compose.SelectType(numbers.Number) + (compose.SelectType(str) | preprocessing.OneHotEncoder())) |\n",
    "    preprocessing.StandardScaler() | linear_model.LinearRegression()\n",
    ")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muito mais leg√≠vel, na minha humilde opini√£o!\n",
    "\n",
    "Existem v√°rias possibilidades com `compose` e Pipelines. Um bom ponto de partida: [The art of using pipelines](https://riverml.xyz/latest/examples/the-art-of-using-pipelines/).\n",
    "\n",
    "Algumas delas ser√£o melhor abordadas no exemplo da pr√≥xima se√ß√£o. A documenta√ß√£o do m√≥dulo √© bem completa, vale a pena conferir!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Exemplo completo\n",
    "\n",
    "Nesse exemplo iremos aplicar todos os conceitos vistos anteriormente.\n",
    "\n",
    "**Aten√ß√£o:**\n",
    "\n",
    "> O objetivo aqui √© aplica√ß√£o de conhecimento, e n√£o lidar com o problema preditivo em si.\n",
    "\n",
    "Provavelmente a extra√ß√£o de melhores features melhoraria o desempenho preditivo do regressor.\n",
    "\n",
    "O dataset a ser utilizado √© um subconjunto do [Airlines](https://kt.ijs.si/elena_ikonomovska/data.html). Utilizaremos dois anos do conjunto total. O dataset deve ser extra√≠do para a mesma pasta deste notebook.\n",
    "\n",
    "O dataset conta com mais de 15 milh√µes de amostras referentes a v√¥os realizados no per√≠odo mencionado. O objetivo √© prever o atraso de cada v√¥o em minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import datetime as dt\n",
    "import functools\n",
    "import numbers\n",
    "import random\n",
    "\n",
    "from river import compose\n",
    "from river import drift\n",
    "from river import evaluate\n",
    "from river import feature_extraction\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from river import rules\n",
    "from river import stats\n",
    "from river import stream\n",
    "from river import time_series\n",
    "from river import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_some(rng, p):\n",
    "    def parser(x, rng=rng, p=p):\n",
    "        if rng.random() <= p:\n",
    "            return None\n",
    "        else:\n",
    "            return float(x)\n",
    "    return parser\n",
    "\n",
    "\n",
    "feature_converters =  {\n",
    "    \"Year\": int,\n",
    "    \"Month\": int,\n",
    "    \"DayofMonth\": int,\n",
    "    \"DayofWeek\": int,\n",
    "    \"CRSDepTime\": str,\n",
    "    \"CRSArrTime\": str,\n",
    "    \"UniqueCarrier\": str,\n",
    "    \"FlightNum\": int,\n",
    "    \"ActualElapsedTime\": float,\n",
    "    \"Origin\": str,\n",
    "    \"Dest\": str,\n",
    "    \"Distance\": drop_some(random.Random(7), p=0.01),\n",
    "    \"Diverted\": lambda d: \"yes\" if d == 1 else \"no\",\n",
    "    \"ArrDelay\": float,\n",
    "} \n",
    "\n",
    "\n",
    "dataset = stream.iter_csv(\n",
    "    \"airlines07_08.csv\",\n",
    "    target=\"ArrDelay\",\n",
    "    converters=feature_converters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes √∫teis\n",
    "def slice_data(dataset, max_samples=2000000):\n",
    "    dataset = iter(dataset)\n",
    "    for i, (x, y) in enumerate(dataset):\n",
    "        yield x, y\n",
    "        \n",
    "        if i == max_samples:\n",
    "            return\n",
    "\n",
    "def parse_date(x):\n",
    "    x = x.copy()\n",
    "    \n",
    "    # Adiciona digitos faltantes\n",
    "    departure = x[\"CRSDepTime\"]\n",
    "    while len(departure) < 4:\n",
    "        departure = \"0\" + departure\n",
    "    \n",
    "    arrival = x[\"CRSArrTime\"]\n",
    "    while len(arrival) < 4:\n",
    "        arrival = \"0\" + arrival\n",
    "    \n",
    "    x.pop(\"CRSDepTime\", None)\n",
    "    x.pop(\"CRSArrTime\", None)\n",
    "        \n",
    "    departure = dt.datetime.strptime(departure, \"%H%M\")\n",
    "    arrival = dt.datetime.strptime(arrival, \"%H%M\")\n",
    "    duration = dt.timedelta(minutes=x[\"ActualElapsedTime\"])\n",
    "    \n",
    "    diff = (arrival - departure) - duration\n",
    "    x[\"approx_time_zone_diff_min\"] = (diff.seconds // 3600) * 60 + ((diff.seconds // 60) % 60) \n",
    "    x[\"est_delay\"] = ((arrival - duration) + diff) - departure\n",
    "    x[\"exp_dep_hour\"] = departure.hour\n",
    "    x[\"exp_dep_minute\"] = departure.minute\n",
    "    x[\"exp_arr_hour\"] = arrival.hour\n",
    "    x[\"exp_arr_minute\"] = arrival.minute\n",
    "    x[\"Month\"] = calendar.month_name[x[\"Month\"]]\n",
    "    x[\"DayofWeek\"] = calendar.day_abbr[x[\"DayofWeek\"] - 1]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_imputer = preprocessing.StatImputer((\"Distance\", stats.Mean()))\n",
    "p_time = compose.FuncTransformer(parse_date)\n",
    "p_discard = compose.Discard(\"Origin\", \"Dest\", \"UniqueCarrier\")\n",
    "p_cat = compose.SelectType(str) | preprocessing.OneHotEncoder()\n",
    "p_num = compose.SelectType(numbers.Number) | preprocessing.StandardScaler()\n",
    "\n",
    "p_extraction = (\n",
    "    feature_extraction.TargetAgg(\n",
    "        by=[\"DayofWeek\", \"UniqueCarrier\"],\n",
    "        how=stats.EWMean(0.8),\n",
    "        target_name=\"delay\"\n",
    "    )\n",
    "    + feature_extraction.TargetAgg(\n",
    "        by=[\"Origin\", \"Dest\"],\n",
    "        how=stats.EWMean(0.8),\n",
    "        target_name=\"delay\"\n",
    "    )\n",
    "    + feature_extraction.TargetAgg(\n",
    "        by=[\"Origin\", \"UniqueCarrier\"],\n",
    "        how=stats.EWMean(0.8),\n",
    "        target_name=\"delay\"\n",
    "    )\n",
    "    + feature_extraction.TargetAgg(\n",
    "        by=[\"Dest\", \"UniqueCarrier\"],\n",
    "        how=stats.EWMean(0.8),\n",
    "        target_name=\"delay\"\n",
    "    )\n",
    "    + feature_extraction.TargetAgg(\n",
    "        by=[\"Origin\", \"Dest\", \"UniqueCarrier\"],\n",
    "        how=stats.EWMean(0.8),\n",
    "        target_name=\"delay\"\n",
    "    )\n",
    "    + feature_extraction.TargetAgg(\n",
    "        by=[\"Origin\", \"Dest\", \"UniqueCarrier\", \"FlightNum\"],\n",
    "        how=stats.EWMean(0.8),\n",
    "        target_name=\"delay\"\n",
    "    )\n",
    ")\n",
    "\n",
    "preproc = p_imputer | p_time | (p_extraction + p_discard) | (p_cat + p_num)\n",
    "preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regressor = rules.AMRules(\n",
    "    n_min=1000,\n",
    "    m_min=100,\n",
    "    drift_detector=drift.ADWIN(0.01),\n",
    "    pred_type=\"adaptive\",\n",
    "    splitter=tree.splitter.QOSplitter(0.5),\n",
    "    tau=0.005,\n",
    "    ordered_rule_set=False,\n",
    "    pred_model=linear_model.PARegressor(C=0.7, eps=5)\n",
    ")\n",
    "\n",
    "metric = metrics.Rolling(metrics.MAE(), 10000)\n",
    "\n",
    "model = preproc | regressor\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate.progressive_val_score(\n",
    "    slice_data(dataset),\n",
    "    model,\n",
    "    metric,\n",
    "    show_memory=True,\n",
    "    show_time=True,\n",
    "    print_every=10000,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
